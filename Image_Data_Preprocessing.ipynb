{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPBQ+8qxuWY8ddsZPHrFVOr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Projects-/blob/master/Image_Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoJguzcGs-Nl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "zyhCQTrbtkrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the realm of machine learning and computer vision, the quality of your model's output heavily relies on the quality of the input data. Image data preprocessing is a crucial step that can significantly influence the performance of your model.\n",
        "When given a dataset, the preprocessing can have various steps depending on\n",
        "a) what type of data you're looking at (text, images, time series, ...)\n",
        "b) what models you want to train\n",
        "\n",
        "This blog will walk you through the essentials of image data preprocessing in Python, using popular libraries like OpenCV, PIL, and TensorFlow."
      ],
      "metadata": {
        "id": "tAetzagZuYVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Table of Content**"
      ],
      "metadata": {
        "id": "as1io-BBv6dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   What is image Preprocessing\n",
        "2.   Tools and Libraries\n",
        "3.   Image Preprocessing steps\n",
        "\n"
      ],
      "metadata": {
        "id": "jOdaFUjYv_Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is image preprocessing?**"
      ],
      "metadata": {
        "id": "m_BpZaqYvsrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is preprocessing?**\n",
        "\n",
        "Def: Preprocessing describes the process of cleaning and converting a 'raw' (i.e. unprocessed) dataset into a clean dataset.\n",
        "\n",
        "Def: Image preprocessing is the process of manipulating raw image data into a usable and meaningful format. It allows you to eliminate unwanted distortions and enhance specific qualities essential for computer vision applications."
      ],
      "metadata": {
        "id": "hpKA6khTt5h3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Image Data Preprocessing?**"
      ],
      "metadata": {
        "id": "BsWVYXS4ufae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before feeding images into a machine learning model, preprocessing is necessary for several reasons:\n",
        "\n",
        "1- Normalization: Ensures that pixel values are within a specific range.\n",
        "\n",
        "2- Resizing: Standardizes the input size for uniformity.\n",
        "\n",
        "3- Augmentation: Increases the diversity of the training data without actually collecting new data.\n",
        "\n",
        "4- Noise Reduction: Removes unwanted artifacts that can distort the image."
      ],
      "metadata": {
        "id": "ncN3SYo2uoxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T**ools and Libraries**"
      ],
      "metadata": {
        "id": "iYE36oAev0Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Several libraries exist that make it easier to preprocess images. For example, you can use **scikit-image**, **OpenCV **or **Pillow**. Each library has different functionalities, pros and cons. In this notebook we will stick to scikit-image."
      ],
      "metadata": {
        "id": "-vM4oS7ty9m9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tools and Libraries**"
      ],
      "metadata": {
        "id": "KAI3PRWAu53u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python offers several libraries to handle image data preprocessing:\n",
        "\n",
        "1- **OpenCV:** A powerful library for computer vision tasks.\n",
        "\n",
        "2- **PIL (Pillow):** A Python Imaging Library that adds image processing capabilities.\n",
        "\n",
        "3- **TensorFlow:** An end-to-end open-source platform for machine learning that includes preprocessing utilities.\n",
        "\n",
        "4-  **scikit-image** scikit-image is a collection of algorithms for image processing.\n",
        "\n",
        "Let's dive into some common preprocessing steps using these libraries."
      ],
      "metadata": {
        "id": "cP3wQQP7u7--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Data Preprocessing Steps**"
      ],
      "metadata": {
        "id": "KBFBb8bdwbQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned already, the preprocessing steps you will need for your dataset depend on the nature of the dataset and models you want to train. Possible preprocessing steps for images are:"
      ],
      "metadata": {
        "id": "F--KO5uaxq_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Loading**"
      ],
      "metadata": {
        "id": "xPX1gLH5woFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting images ready for use means taking them from wherever they're stored and bringing them into memory. You can do this with tools like PIL or OpenCV. This makes the images easier to work with and study."
      ],
      "metadata": {
        "id": "yRDmcobOxNMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZdEkqkbysO-",
        "outputId": "6ff9a590-a60d-41c5-e18c-dc612f0c56c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import random\n",
        "import matplotlib\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import io\n",
        "from skimage import img_as_float\n",
        "from skimage.transform import resize, rotate\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "KQMdIST90Epv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of all images\n",
        "root_path = os.path.expanduser('~/ml_basics/images/')\n",
        "all_images = glob.glob(root_path + '/*.jpg')\n",
        "# To avoid memory errors we will only use a subset of the images\n",
        "all_images = random.sample(all_images, 500)"
      ],
      "metadata": {
        "id": "Lfa_Ak290qt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a few images\n",
        "i = 0\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for img_path in all_images[:4]:\n",
        "    img_arr = io.imread(img_path)\n",
        "    i += 1\n",
        "    ax = fig.add_subplot(2, 2, i)\n",
        "    ax.imshow(img_arr)\n",
        "    ax.set_title(f\"Image example {i}\")"
      ],
      "metadata": {
        "id": "dz8ZT-lH1F7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using OpenCV**"
      ],
      "metadata": {
        "id": "7EAcPo9RIyHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load an image using OpenCV\n",
        "image = cv2.imread('path_to_image.jpg')\n"
      ],
      "metadata": {
        "id": "wairWsK2I0Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using PIL**"
      ],
      "metadata": {
        "id": "dgIuRLt3I3XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Load an image using PIL\n",
        "image = Image.open('path_to_image.jpg')\n"
      ],
      "metadata": {
        "id": "iDodJdFEJA7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rescale the images**"
      ],
      "metadata": {
        "id": "tNMpnUGD3_qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing images changes their dimensions (height and width) to a standard size, which is crucial for ensuring uniform input sizes for machine learning models.\n",
        "\n",
        "This step is important because most neural networks require fixed input dimensions.\n",
        "\n",
        "The images displayed above show us that the dataset has images with various scales. So, as a first preprocessing step, we will make sure that all images have the same height and width. When choosing an appropriate size we should keep in mind that bigger images correspond to higher computational requirements (both memory and operation wise).\n",
        "\n",
        "As a first step we should figure out the dimensions of our images."
      ],
      "metadata": {
        "id": "i7xH2mZ54RL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_sizes = [io.imread(img).shape for img in all_images]\n",
        "\n",
        "heights = [img_shape[0] for img_shape in all_sizes]\n",
        "widths = [img_shape[1] for img_shape in all_sizes]\n",
        "\n",
        "print(f\"Minimum image height: {min(heights)}\")\n",
        "print(f\"Maximum image height: {max(heights)}\")\n",
        "print()\n",
        "print(f\"Minimum image width: {min(widths)}\")\n",
        "print(f\"Maximum image width: {max(widths)}\")"
      ],
      "metadata": {
        "id": "NbM5zNMY4fxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will resize the images to\n",
        " pixels using scikit-image (other shapes would be fine, too). The images won't be cropped but up-sized or down-sized using interpolation.\n",
        "\n",
        "Further, for simplicity, we will skip images that have less or more than 3 color channels (i.e. images whose mode is not RGB). As a quick reminder:"
      ],
      "metadata": {
        "id": "wmc_VhOL4sSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RGB is a 3-channel format corresponding to the channels red, green and blue. RGBA is a 4-channel format corresponding to red, green, blue and alpha. The alpha channel makes the color of the image transparant or translucent.\n",
        "\n",
        "Note: make sure to create a folder named \"resized_images\", otherwise the code below will raise an error!"
      ],
      "metadata": {
        "id": "HkZXpGYt5ZC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resized_path = os.path.join(root_path, 'resized_images/')\n",
        "\n",
        "for img_path in all_images:\n",
        "    # Create a new image name to save the resized image\n",
        "    img_name = img_path.split('/')[-1]\n",
        "    img_name = os.path.splitext(img_name)\n",
        "    resized_name = img_name[0] + '_resized' + img_name[1]\n",
        "    save_path = os.path.join(resized_path, resized_name)\n",
        "\n",
        "    img = io.imread(img_path)\n",
        "\n",
        "    if img.ndim != 3 or img.shape[2] != 3:\n",
        "        continue\n",
        "\n",
        "    resized_img = resize(img, output_shape=(256, 256))\n",
        "    io.imsave(save_path, resized_img)\n",
        "all_images = glob.glob(resized_path + '/*')"
      ],
      "metadata": {
        "id": "_8H2X1vA5i1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a few images\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "i = 0\n",
        "for img_path in all_images[:4]:\n",
        "    img_arr = io.imread(img_path)\n",
        "    i += 1\n",
        "    ax = fig.add_subplot(2, 2, i)\n",
        "    ax.imshow(img_arr)\n",
        "    ax.set_title(f\"Resized image example {i}\")"
      ],
      "metadata": {
        "id": "j8j7nsAu5mQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using OpenCV**"
      ],
      "metadata": {
        "id": "bEvC-_QTJJCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the image to 224x224 pixels\n",
        "resized_image = cv2.resize(image, (224, 224))\n"
      ],
      "metadata": {
        "id": "SOa_rVASJMkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using PIL**"
      ],
      "metadata": {
        "id": "x_Ss7Qo2JNmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the image to 224x224 pixels\n",
        "resized_image = image.resize((224, 224))\n"
      ],
      "metadata": {
        "id": "8OAdYW6mJVP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Normalizing pixel values**"
      ],
      "metadata": {
        "id": "nnlx-1yj5rRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically, normalizing pixel values means adjusting the intensity of pixels in an image to a set range like [0, 1] or [-1, 1]. This is done by dividing the pixel values by the maximum possible value (e.g., 255 for an 8-bit image). Normalization is important for making machine learning models train faster and more effectively by keeping input features on a consistent scale. This helps with stability and overall performance."
      ],
      "metadata": {
        "id": "6a10cnOa63od"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing pixel values has two steps:\n",
        "\n",
        "**Mean subtraction:** in the case of images this often refers to subtracting the mean computed over all images from each pixel. The mean value can be computed over all three channels or for each channel individually. As described in the given link this has the \"geometric interpretation of centering the cloud of data around the origin along every dimension\".\n",
        "\n",
        "**Divide by standard deviation:** This step is not strictly necessary for images because the relative pixel scales are already approximately equal. Nevertheless, we will include this step for completeness."
      ],
      "metadata": {
        "id": "FVz298tb6_Zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To compute the mean and standard deviation over all images\n",
        "# we need to combine them in one big array\n",
        "big_list = []\n",
        "\n",
        "for img_path in all_images:\n",
        "    big_list.append(io.imread(img_path))\n",
        "\n",
        "all_imgs = np.array(big_list)\n",
        "\n",
        "# The image pixels are uint8. To compute a mean we\n",
        "# convert the pixel values to floats\n",
        "all_imgs_float = img_as_float(all_imgs)\n",
        "\n",
        "# Mean subtraction\n",
        "mean = np.mean(all_imgs_float, axis=0)\n",
        "all_imgs_float -= mean\n",
        "\n",
        "# Dividing by standard deviation\n",
        "std = np.std(all_imgs_float, axis=0)\n",
        "all_imgs_float /= std\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i in range(9):\n",
        "    ax = fig.add_subplot(3, 3, i+1)\n",
        "    ax.imshow(all_imgs_float[i])\n",
        "    ax.set_title(f\"Normalized image example {i+1}\")"
      ],
      "metadata": {
        "id": "7fOWeEfWIi_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using OpenCV**"
      ],
      "metadata": {
        "id": "3Nq-6sp0JXG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to [0, 1]\n",
        "normalized_image = image / 255.0\n"
      ],
      "metadata": {
        "id": "y9qgEHj5JgVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Converting to grayscale**"
      ],
      "metadata": {
        "id": "xZFRkTT3Jl6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting color images to grayscale can simplify your image data and reduce computational needs for some algorithms."
      ],
      "metadata": {
        "id": "1XXROWgFMu8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the images to grayscale is very easy with scikit-image.\n",
        "\n"
      ],
      "metadata": {
        "id": "69Fy84zKJu10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gray_images = rgb2gray(all_imgs)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(4):\n",
        "    ax = fig.add_subplot(2, 2, i+1)\n",
        "    ax.imshow(gray_images[i], cmap='gray')\n",
        "    ax.set_title(f\"Grayscale image example {i+1}\")"
      ],
      "metadata": {
        "id": "ioRcX040J4zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data augmentation**"
      ],
      "metadata": {
        "id": "m4KB7mcaJ6gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image augmentation is a technique to artificially increase the size of a dataset by creating modified versions of images. Common augmentations include rotation, flipping, and zooming."
      ],
      "metadata": {
        "id": "JLwd4hBrKIb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all: why do we need data augmentation?\n",
        "\n",
        "The performance of a machine learning algorithm depends heavily on the amount and quality of the data it is trained with. In most cases, the more data a machine learning algorithm has access to, the more effective it can be. However, most of the time, we only have access to a small amount of data with sufficient quality. So, if we augment our dataset in a useful way we can improve the performance of our model without having to gather a larger dataset.\n",
        "\n",
        "Furthermore, augmenting the dataset can make our model more robust. For example, consider the task of image classification. Let's say we want to classify the breed of dog/cat shown in each image of our dataset. Our training set will contain only a limited amount of images each breed, and each breed will be displayed in a limited set of conditions. However, our test set (or real world application) may contain images of dogs and cats in a large variety of conditions. The images could be taken from various angles, locations, lighting conditions, etc. By augmenting our training set with small variations of the original images, we can allow our model to account for such variations.\n",
        "\n",
        "Images can be augmented in various ways, for example using:"
      ],
      "metadata": {
        "id": "7GdsqlXwK4Uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- rotation\n",
        "\n",
        "2- translation\n",
        "\n",
        "3- rescaling\n",
        "\n",
        "4- lipping\n",
        "\n",
        "5- stretching etc."
      ],
      "metadata": {
        "id": "OtxfQsnpK-VE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**scikit-image**"
      ],
      "metadata": {
        "id": "vHu0UKbTLMCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of these tasks can be performed easily with scikit-image or one of the other image processing libraries. Let's look at rotation as an example."
      ],
      "metadata": {
        "id": "2u1JEdIlLYJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(4):\n",
        "    random_angle = np.random.randint(low=0, high=360)\n",
        "    rotated_image = rotate(all_imgs[i], angle=random_angle)\n",
        "    ax = fig.add_subplot(2, 2, i+1)\n",
        "    ax.imshow(rotated_image)\n",
        "    ax.set_title(f\"Randomly rotated image example {i+1}\")"
      ],
      "metadata": {
        "id": "OBEGevpfLXes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using TensorFlow**\n",
        "\n",
        "TensorFlow provides a high-level API for image augmentation."
      ],
      "metadata": {
        "id": "QIbYL6PAKOC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an image data generator with augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Assuming 'image' is a numpy array of shape (height, width, channels)\n",
        "image = image.reshape((1, ) + image.shape)  # Reshape image for the generator\n",
        "\n",
        "# Generate batches of augmented images\n",
        "for batch in datagen.flow(image, batch_size=1):\n",
        "    augmented_image = batch[0]\n",
        "    break  # To generate one augmented image\n"
      ],
      "metadata": {
        "id": "5i-tHx2pKSZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Noise Reduction**"
      ],
      "metadata": {
        "id": "rgvRY9tRKXZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reducing noise can help improve the clarity of the image and the performance of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "90j_0GQaKdhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smoothing, blurring, and filtering techniques can be applied to remove unwanted noise from images. The GaussianBlur () and medianBlur () methods are commonly used for this."
      ],
      "metadata": {
        "id": "flQRT1aTM2vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using OpenCV**\n"
      ],
      "metadata": {
        "id": "OF36VFoPKgj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply GaussianBlur to reduce noise\n",
        "denoised_image = cv2.GaussianBlur(image, (5, 5), 0)\n"
      ],
      "metadata": {
        "id": "2O_oNS_lKlUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "nRWAvs7sKqXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "Effective image data preprocessing is a critical step in building robust and high-performing machine learning models. By leveraging libraries such as OpenCV, PIL, and TensorFlow, you can streamline this process and ensure your images are in the best possible shape for model training. Whether it's resizing, normalizing, augmenting, or reducing noise, each step enhances the quality of your input data and, consequently, the performance of your model."
      ],
      "metadata": {
        "id": "WQGJqY4lKwMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**"
      ],
      "metadata": {
        "id": "EnXgqoAwtCLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1- Image Preprocessing](https://github.com/zotroneneis/machine_learning_basics/blob/master/image_preprocessing.ipynb)"
      ],
      "metadata": {
        "id": "XajAujBrtLE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2-Image Data Preprocessing Techniques You Should Know](https://thecleverprogrammer.com/2024/06/05/image-data-preprocessing-techniques-you-should-know/?fbclid=IwZXh0bgNhZW0CMTEAAR2Qfq3em9lQDc4msZcLMmimg9nPX-RvBKMZPVNg40Tn_q5e1UK9kHfOl18_aem_ZmFrZWR1bW15MTZieXRlcw)\n",
        "\n",
        "[3-Why normalize images by subtracting dataset's image mean, instead of the current image mean in deep learning?](https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current)\n",
        "\n",
        "[4-The Complete Guide to Image Preprocessing Techniques in Python](https://medium.com/@maahip1304/the-complete-guide-to-image-preprocessing-techniques-in-python-dca30804550c)"
      ],
      "metadata": {
        "id": "tke95LbitTId"
      }
    }
  ]
}