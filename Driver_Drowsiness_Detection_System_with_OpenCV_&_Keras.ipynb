{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Driver Drowsiness Detection System with OpenCV & Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Projects-/blob/master/Driver_Drowsiness_Detection_System_with_OpenCV_%26_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS",
        "colab_type": "text"
      },
      "source": [
        "# Driver Drowsiness Detection\n",
        "# **Introduction:**\n",
        "\n",
        "With this intermediate-level Python project, we will be making a drowsiness detecting device. A countless number of people drive on the highway day and night. Taxi drivers, bus drivers, truck drivers and people traveling long-distance suffer from lack of sleep. Due to which it becomes very dangerous to drive when feeling sleepy.\n",
        "\n",
        "The majority of accidents happen due to the drowsiness of the driver. So, to prevent these accidents we will build a system using Python, OpenCV, and Keras which will alert the driver when he feels sleepy.[1].\n",
        "\n",
        "In this Python project, we will be using OpenCV for gathering the images from webcam and feed them into a Deep Learning model which will classify whether the person’s eyes are ‘Open’ or ‘Closed’. The approach we will be using for this Python project is as follows [1] :\n",
        "\n",
        "Step 1 – Take image as input from a camera.\n",
        "\n",
        "Step 2 – Detect the face in the image and create a Region of Interest (ROI).\n",
        "\n",
        "Step 3 – Detect the eyes from ROI and feed it to the classifier.\n",
        "\n",
        "Step 4 – Classifier will categorize whether eyes are open or closed.\n",
        "\n",
        "Step 5 – Calculate score to check whether the person is drowsy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnY7VuCDI-qN",
        "colab_type": "text"
      },
      "source": [
        "# 1 **Training the Dataset**#\n",
        "\n",
        "The dataset used for this model is created by us. To create the dataset, we wrote a script that captures eyes from a camera and stores in our local disk. We separated them into their respective labels ‘Open’ or ‘Closed’. The data was manually cleaned by removing the unwanted images which were not necessary for building the model. The data comprises around 7000 images of people’s eyes under different lighting conditions. After training the model on our dataset, we have attached the final weights and model architecture file “models/cnnCat2.h5”.[1]\n",
        "\n",
        "Now, you can use this model to classify if a person’s eye is open or closed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu9n3L_N2RnJ",
        "colab_type": "text"
      },
      "source": [
        "#**2-The Model Architecture**\n",
        "The model we used is built with Keras using Convolutional Neural Networks (CNN). A convolutional neural network is a special type of deep neural network which performs extremely well for image classification purposes. A CNN basically consists of an input layer, an output layer and a hidden layer which can have multiple numbers of layers. A convolution operation is performed on these layers using a filter that performs 2D matrix multiplication on the layer and filter.\n",
        "\n",
        "The CNN model architecture consists of the following layers:\n",
        "\n",
        "- Convolutional layer; 32 nodes, kernel size 3\n",
        "- Convolutional layer; 32 nodes, kernel size 3\n",
        "- Convolutional layer; 64 nodes, kernel size 3\n",
        "- Fully connected layer; 128 nodes\n",
        "- The final layer is also a fully connected layer with 2 nodes. In all the layers, a Relu activation function is used except the output layer in which we used Softmax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSEe67Vxm-i9",
        "colab_type": "text"
      },
      "source": [
        "#**3-Prerequisites**\n",
        "\n",
        "The requirement for this Python project is a webcam through which we will capture images. You need to have Python (3.6 version recommended) installed on your system, then using pip, you can install the necessary packages.\n",
        "\n",
        "- OpenCV – pip install opencv-python (face and eye detection).\n",
        "- TensorFlow – pip install tensorflow (keras uses TensorFlow as backend).\n",
        "- Keras – pip install keras (to build our classification model).\n",
        "- Pygame – pip install pygame (to play alarm sound)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZwlcFz6h8cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pygame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCeIlr5F4iHc",
        "colab_type": "text"
      },
      "source": [
        "**SciPy**\n",
        "\n",
        "we can compute the Euclidean distance between facial landmarks points in the eye aspect ratio calculation (not strictly a requirement, but you should have SciPy installed if you intend on doing any work in the computer vision, image processing, or machine learning space)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhUSWOny41q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAkVNIse47RD",
        "colab_type": "text"
      },
      "source": [
        "**imutils package**\n",
        "\n",
        "We’ll also need the imutils package, my series of computer vision and image processing functions to make working with OpenCV easier.\n",
        "\n",
        "If you don’t already have imutils  installed on your system, you can install/upgrade imutils  via:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNKcSK3J5KYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade imutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a988H4565Zn4",
        "colab_type": "text"
      },
      "source": [
        " **Playsound library**\n",
        "\n",
        " We’ll also import the Thread  class so we can play our alarm in a separate thread from the main thread to ensure our script doesn’t pause execution while the alarm sounds.\n",
        "\n",
        "In order to actually play our WAV/MP3 alarm, we need the playsound library, a pure Python, cross-platform implementation for playing simple sounds.\n",
        "\n",
        "The playsound  library is conveniently installable via pip :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiLCXMqU5phl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install playsound"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAVZc4ayyDWL",
        "colab_type": "text"
      },
      "source": [
        "# **4-Installing Library** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy8GBKBY99lX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from scipy.spatial import distance as dist\n",
        "from imutils.video import VideoStream\n",
        "from imutils import face_utils\n",
        "from threading import Thread\n",
        "import numpy as np\n",
        "import playsound\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import dlib\n",
        "import cv2\n",
        " "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQFJb0YzEYO",
        "colab_type": "text"
      },
      "source": [
        "#5 - **Upload Loca files** # "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hncBMFUXFN6G",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "92e3faa4-c760-44b2-f939-f91c9742b63d"
      },
      "source": [
        "# this code is used to upload dataset from Pc to colab\n",
        "from google.colab import files # Please First run this cod in chrom \n",
        "def getLocalFiles():\n",
        "    _files = files.upload() # upload StudentNextSessionf.csv datase\n",
        "    if len(_files) >0: # Then run above  libray \n",
        "       for k,v in _files.items():\n",
        "         open(k,'wb').write(v)\n",
        "getLocalFiles()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-524c577e-710f-42f4-949a-d04d1dd792a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-524c577e-710f-42f4-949a-d04d1dd792a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving alarm.wav to alarm.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpHsrVexXuWj",
        "colab_type": "text"
      },
      "source": [
        "#**6-Play Audio file**\n",
        "Next, we need to define our sound_alarm  function which accepts a path  to an audio file residing on disk and then plays the file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSQEdUrE7Tje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sound_alarm(path):\n",
        "\t# play an alarm sound\n",
        "\tplaysound.playsound(path)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL",
        "colab_type": "text"
      },
      "source": [
        "# 7- **eye_aspect_ratio**\n",
        "\n",
        "We also need to define the eye_aspect_ratio  function which is used to compute the ratio of distances between the vertical eye landmarks and the distances between the horizontal eye landmarks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6333A5woSWX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eye_aspect_ratio(eye):\n",
        "\t# compute the euclidean distances between the two sets of\n",
        "\t# vertical eye landmarks (x, y)-coordinates\n",
        "\tA = dist.euclidean(eye[1], eye[5])\n",
        "\tB = dist.euclidean(eye[2], eye[4])\n",
        "\t# compute the euclidean distance between the horizontal\n",
        "\t# eye landmark (x, y)-coordinates\n",
        "\tC = dist.euclidean(eye[0], eye[3])\n",
        "\t# compute the eye aspect ratio\n",
        "\tear = (A + B) / (2.0 * C)\n",
        "\t# return the eye aspect ratio\n",
        "\treturn ear"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEE-rIGb8OA7",
        "colab_type": "text"
      },
      "source": [
        "The return value of the eye aspect ratio will be approximately constant when the eye is open. The value will then rapid decrease towards zero during a blink.\n",
        "\n",
        "If the eye is closed, the eye aspect ratio will again remain approximately constant, but will be much smaller than the ratio when the eye is open."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q",
        "colab_type": "text"
      },
      "source": [
        "#8- **Construct the argument parse and parse the arguments** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-p\", \"--shape-predictor\", required=True,\n",
        "\thelp=\"path to facial landmark predictor\")\n",
        "ap.add_argument(\"-a\", \"--alarm\", type=str, default=\"\",\n",
        "\thelp=\"path alarm .WAV file\")\n",
        "ap.add_argument(\"-w\", \"--webcam\", type=int, default=0,\n",
        "\thelp=\"index of webcam on system\")\n",
        "args = vars(ap.parse_args())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylnFgE7Z-XBt",
        "colab_type": "text"
      },
      "source": [
        "Our drowsiness detector requires one command line argument followed by two optional ones, each of which is detailed below:\n",
        "\n",
        "- shape-predictor : This is the path to dlib’s pre-trained facial landmark detector. You can download the detector along with the source code to this tutorial by using the “Downloads” section at the bottom of this blog post.\n",
        "- alarm : Here you can optionally specify the path to an input audio file to be used as an alarm.\n",
        "- webcam : This integer controls the index of your built-in webcam/USB camera."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-",
        "colab_type": "text"
      },
      "source": [
        "# 9- **Define a few important variables:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTMzvER1BcHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define two constants, one for the eye aspect ratio to indicate\n",
        "# blink and then a second constant for the number of consecutive\n",
        "# frames the eye must be below the threshold for to set off the\n",
        "# alarm\n",
        "EYE_AR_THRESH = 0.3\n",
        "EYE_AR_CONSEC_FRAMES = 48\n",
        "# initialize the frame counter as well as a boolean used to\n",
        "# indicate if the alarm is going off\n",
        "COUNTER = 0\n",
        "ALARM_ON = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp-1eQaeBoa8",
        "colab_type": "text"
      },
      "source": [
        "- EYE_AR_THRESH . If the eye aspect ratio falls below this threshold, we’ll start counting the number of frames the person has closed their eyes for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrgUo8fTbXz",
        "colab_type": "text"
      },
      "source": [
        "##5.1- **1st convolution layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()  \n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))  \n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))  \n",
        "# model.add(BatchNormalization())  \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
        "model.add(Dropout(0.5))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 - **2nd Convolution Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(64, (3, 3), activation='relu'))  \n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))  \n",
        "# model.add(BatchNormalization())  \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
        "model.add(Dropout(0.5)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLfUeKr2UNe7",
        "colab_type": "text"
      },
      "source": [
        "## 5.3- **3rd Convolution Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUJ16arHaKMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(128, (3, 3), activation='relu'))  \n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))  \n",
        "# model.add(BatchNormalization())  \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
        "model.add(Flatten())  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7EabEFjUl6t",
        "colab_type": "text"
      },
      "source": [
        "##5.4-  **Fully connected neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_XHGn_oUvMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(1024, activation='relu'))  \n",
        "model.add(Dropout(0.2))  \n",
        "model.add(Dense(1024, activation='relu'))  \n",
        "model.add(Dropout(0.2))  \n",
        "model.add(Dense(num_labels, activation='softmax'))  \n",
        "# model.summary()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-DCjB-Io3j7",
        "colab_type": "text"
      },
      "source": [
        "#**6-Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V_1M1FnMN2O",
        "colab_type": "text"
      },
      "source": [
        "##**6.1 Method1 Generator [2]**\n",
        "We can train the network. To complete the training in less time, I prefer to implement learning with randomly selected trainset instances. That is the reason why train and fit generator used. Also, loss function would be cross entropy because the task is multi class classification [2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc_KJ0lWlm8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1KyuvVXMRbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "gen = ImageDataGenerator()\n",
        "train_generator = gen.flow(X_train, train_y, batch_size=batch_size)\n",
        "model.compile(loss='categorical_crossentropy'\n",
        ", optimizer=keras.optimizers.Adam()\n",
        ", metrics=['accuracy']\n",
        ")\n",
        "model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOCxPs8sU5aP",
        "colab_type": "text"
      },
      "source": [
        "##6.2-**Method 2 Compliling the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi-DFb_OVBr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=categorical_crossentropy,  \n",
        "              optimizer=Adam(),  \n",
        "              metrics=['accuracy'])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02q29lEXVRjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, train_y,  \n",
        "          batch_size=batch_size,  \n",
        "          epochs=epochs,  \n",
        "          verbose=1,  \n",
        "          validation_data=(X_test, test_y),  \n",
        "          shuffle=True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKCwzVMnVaOm",
        "colab_type": "text"
      },
      "source": [
        "#7-**Saving the  model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-PUeUv-VglW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fer_json = model.to_json()  \n",
        "with open(\"fer.json\", \"w\") as json_file:  \n",
        "    json_file.write(fer_json)  \n",
        "model.save_weights(\"fer.h5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtpS-joPfJqi",
        "colab_type": "text"
      },
      "source": [
        "#8-**Evaluate model [2]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S05tU0VfhVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_score = model.evaluate(X_train, train_y, verbose=0)\n",
        "print('Train loss:', train_score[0])\n",
        "print('Train accuracy:', 100*train_score[1])\n",
        "test_score = model.evaluate(X_test, test_y, verbose=0)\n",
        "print('Test loss:', test_score[0])\n",
        "print('Test accuracy:', 100*test_score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UC9kS_Rv_hA",
        "colab_type": "text"
      },
      "source": [
        "# **9-Confusion Matrix**[2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmsbOnwbwJTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        " \n",
        "pred_list = []; actual_list = []\n",
        " \n",
        "for i in predictions:\n",
        "  pred_list.append(np.argmax(i))\n",
        " \n",
        "for i in Y_test:\n",
        "  actual_list.append(np.argmax(i))\n",
        " \n",
        "confusion_matrix(actual_list, pred_list)\n",
        "Testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8WWRWP0wh2Z",
        "colab_type": "text"
      },
      "source": [
        "#**10-Testing**[2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjDLBzNZw7Tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "d861f283-6eaf-45de-e6d0-a3112c679f73"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from matplotlib import pyplot as plt\n",
        "img = image.load_img(\"la.jfif\", grayscale=True, target_size=(48, 48))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "x /= 255\n",
        "custom = model.predict(x)\n",
        "emotion_analysis(custom[0])\n",
        "x = np.array(x, 'float32')\n",
        "x = x.reshape([48, 48]);\n",
        "plt.gray()\n",
        "plt.imshow(x)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Te0y5lxDan",
        "colab_type": "text"
      },
      "source": [
        "Emotions stored as numerical as labeled from 0 to 6. Keras would produce an output array including these 7 different emotion scores. We can visualize each prediction as bar chart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyQL0kDKwyxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emotion_analysis(emotions):\n",
        "  objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "  y_pos = np.arange(len(objects))\n",
        "  plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
        "  plt.xticks(y_pos, objects)\n",
        "  plt.ylabel('percentage')\n",
        "  plt.title('emotion')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNk8Y4m5b3tf",
        "colab_type": "text"
      },
      "source": [
        "#**11-Detecting Real-Time Emotion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgAXg8iCb88r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os  \n",
        "import cv2  \n",
        "import numpy as np  \n",
        "from keras.models import model_from_json  \n",
        "from keras.preprocessing import image  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJbt4FopcEyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load model  \n",
        "model = model_from_json(open(\"fer.json\", \"r\").read())  \n",
        "#load weights  \n",
        "model.load_weights('fer.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb9gAA3fcMGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srFH4QN7cNW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap=cv2.VideoCapture(0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxitWGrYcUIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap=cv2.VideoCapture(0)  \n",
        "while True:  \n",
        "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image  \n",
        "    #if not ret:  \n",
        "        #continue  \n",
        "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)  \n",
        "\n",
        "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)  \n",
        "\n",
        "\n",
        "    for (x,y,w,h) in faces_detected:  \n",
        "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)  \n",
        "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image  \n",
        "        roi_gray=cv2.resize(roi_gray,(48,48))  \n",
        "        img_pixels = image.img_to_array(roi_gray)  \n",
        "        img_pixels = np.expand_dims(img_pixels, axis = 0)  \n",
        "        img_pixels /= 255  \n",
        "\n",
        "        predictions = model.predict(img_pixels)  \n",
        "\n",
        "        #find max indexed array  \n",
        "        max_index = np.argmax(predictions[0])  \n",
        "\n",
        "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')  \n",
        "        predicted_emotion = emotions[max_index]  \n",
        "\n",
        "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)  \n",
        "\n",
        "    resized_img = cv2.resize(test_img, (1000, 700))  \n",
        "    cv2.imshow('Facial emotion analysis ',resized_img)  \n",
        "\n",
        "\n",
        "\n",
        "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed  \n",
        "        break  \n",
        "\n",
        "cap.release()  \n",
        "cv2.destroyAllWindows  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "[1] Intermediate Python Project – Driver Drowsiness Detection System with OpenCV & Keras\n",
        "https://data-flair.training/blogs/python-project-driver-drowsiness-detection-system/\n",
        "\n",
        "[1] Building a Real Time Emotion Detection with Python\n",
        "\n",
        "https://morioh.com/p/801c509dda99?f=5c21f93bc16e2556b555ab2f\n",
        "\n",
        "[2] Facial Expression Recognition with Keras\n",
        "http://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/\n",
        "\n",
        "[3]Drowsiness detection with OpenCV\n",
        "https://www.pyimagesearch.com/2017/05/08/drowsiness-detection-opencv/\n",
        "\n"
      ]
    }
  ]
}