{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Gender_and_Age_Detection_Python_Project (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS",
        "colab_type": "text"
      },
      "source": [
        "# Gender and Age Detection (youtube Video and Camera )\n",
        "# **Introduction:**\n",
        "\n",
        "Age and gender, two of the key facial attributes, play a very foundational role in social interactions, making age and gender estimation from a single face image an important task in intelligent applications, such as access control, human-computer interaction, law enforcement, marketing intelligence\n",
        "and visual surveillance, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnY7VuCDI-qN",
        "colab_type": "text"
      },
      "source": [
        "# 1 **Terminologies**#\n",
        "\n",
        "First introducing you with the terminologies used in this advanced python project of gender and age detection "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_aCyhDgoTRK",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 What is Computer Vision? \n",
        "Computer Vision is the field of study that enables computers to see and identify digital images and videos as a human would. The challenges it faces largely follow from the limited understanding of biological vision. Computer Vision involves acquiring, processing, analyzing, and understanding digital images to extract high-dimensional data from the real world in order to generate symbolic or numerical information which can then be used to make decisions. The process often includes practices like object recognition, video tracking, motion estimation, and image restoration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq4DpmTeRNNy",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 What is OpenCV?\n",
        "OpenCV is short for Open Source Computer Vision. Intuitively by the name, it is an open-source Computer Vision and Machine Learning library. This library is capable of processing real-time image and video while also boasting analytical capabilities. It supports the Deep Learning frameworks TensorFlow, Caffe, and PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcVaahYFRsEF",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 What is a CNN?\n",
        "A Convolutional Neural Network is a deep neural network (DNN) widely used for the purposes of image recognition and processing and NLP. Also known as a ConvNet, a CNN has input and output layers, and multiple hidden layers, many of which are convolutional. In a way, CNNs are regularized multilayer perceptrons.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C_dTcsnSGFD",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 The CNN Architecture\n",
        "The convolutional neural network for this python project has 3 convolutional layers:\n",
        "- Convolutional layer; 96 nodes, kernel size 7\n",
        "- Convolutional layer; 256 nodes, kernel size 5\n",
        "- Convolutional layer; 384 nodes, kernel size 3\n",
        "\n",
        "It has 2 fully connected layers, each with 512 nodes, and a final output layer of softmax type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWjlZqTBTeD7",
        "colab_type": "text"
      },
      "source": [
        "# 2. **Requirements** \n",
        "To go about the python project, we’ll install the followng thing\n",
        " - pip install OpenCV-python\n",
        " - numpy\n",
        " - pip install pafy\n",
        " - pip install youtube_dl \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFpml2B59Z2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install OpenCV-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GakzWi089ogd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pafy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2XtKgKx9t_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install youtube_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60oC7JjslreY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install caffe-cpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxnt5T_AWVYz",
        "colab_type": "text"
      },
      "source": [
        "**pafy**\n",
        "\n",
        "pafy : Pafy library is used to retrieve YouTube content and metadata(such as Title, rating, viewcount, duration, rating, author, thumbnail, keywords etc). To know more about pafy. Let's check one sample :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck-TjHEcroay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pafy\n",
        "url = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q4ntvNt_Jm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vPafy = pafy.new(url)\n",
        "print('title:', vPafy.title)\n",
        "print ('rating:', vPafy.rating)\n",
        "print ('View account:',vPafy.viewcount)\n",
        "print ('author:',vPafy.author)\n",
        "print  ('length:', vPafy.length)\n",
        "print ('Description',vPafy.description)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKcybVMDX4g4",
        "colab_type": "text"
      },
      "source": [
        "# 4- **Prerequisites**\n",
        "You’ll need to install OpenCV (cv2) to be able to run this project. You can do this with pip-\n",
        "Other packages you’ll be needing are math and argparse, but those come as part of the standard Python library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkWk8WlsYG7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nhYP15aoCAcf",
        "colab_type": "text"
      },
      "source": [
        "# 5 - **Import library** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wsGi52CAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import pafy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "caffe_root = './caffe/' \n",
        "import sys\n",
        "sys.path.insert(0, caffe_root + 'python')\n",
        "import caffe\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQFJb0YzEYO",
        "colab_type": "text"
      },
      "source": [
        "#6- **Uploadrelated module from local Drive** # "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqD8iiJZzTZj",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "a80c7a71-909e-45bf-f3c1-d0a82f619326"
      },
      "source": [
        "# this code is used to upload dataset from Pc to colab\n",
        "from google.colab import files # Please First run this cod in chrom \n",
        "def getLocalFiles():\n",
        "    _files = files.upload() # upload StudentNextSessionf.csv datase\n",
        "    if len(_files) >0: # Then run above  libray \n",
        "       for k,v in _files.items():\n",
        "         open(k,'wb').write(v)\n",
        "getLocalFiles()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-70857a3f-ef9a-466a-8555-115bf11c6cae\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-70857a3f-ef9a-466a-8555-115bf11c6cae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL",
        "colab_type": "text"
      },
      "source": [
        "# 6- **Get the Youtube video URL**\n",
        "Get the Youtube video URL and try to get the attributes of the video using pafy as explained above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JGZRKCCAcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " url = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'\n",
        "vPafy = pafy.new(url)\n",
        "play = vPafy.getbest(preftype=\"mp4\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q",
        "colab_type": "text"
      },
      "source": [
        "#7- **Capture video from URL or Camera** \n",
        "\n",
        "Often, we have to capture live stream with a camera. OpenCV provides a very simple interface to this. We can capture the video from the camera, convert it into grayscale video and display it. Just a simple task to get started.\n",
        "To capture a video, you need to create a video capture object. Its argument can be either the device index or the name of a video file. Device index is just the number to specify which camera. Normally one camera will be connected (as in my case). So I simply pass 0 (or -1). You can select the second camera by passing 1 and so on. After that, you can capture frame-by-frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture(0) #if you are using webcam"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsa0bQAJD3nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# But in my case I’m reading an online video URL, for that, I’ll pass ‘play’ object to VideoCapture().\n",
        "cap = cv2.VideoCapture(play.url) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-",
        "colab_type": "text"
      },
      "source": [
        "# 8- **Set the height and width of our video frame**\n",
        "Using set() I’ll set the height and width of our video frame. cap.set(propId, value), here 3 is the propertyId of width and 4 is for Height."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap.set(3, 480) #set width of the frame\n",
        "cap.set(4, 640) #set height of the frame "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF",
        "colab_type": "text"
      },
      "source": [
        "# 8 - **Separate lists for storing Model_Mean_Values Age and Gender**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
        "age_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
        "gender_list = ['Male', 'Female']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g78HCuLVCAdG",
        "colab_type": "text"
      },
      "source": [
        "#9- **Pre-trained CNN models**\n",
        "\n",
        "I have defined a function to load caffemodel and prototxt of both age and gender detector, these are basically pre-trained CNN models which will do the detection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTAYjq6JOpj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_caffe_models():\n",
        " age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')\n",
        "gender_net = cv2.dnn.readNetFromCaffe('deploy_gender.prototxt', 'gender_net.caffemodel')\n",
        "return(age_net, gender_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg-zk8uciMg_",
        "colab_type": "text"
      },
      "source": [
        "# 10- **Main function**\n",
        "Now we will perform face detection, Age detection, and Gender detection and for that create a function video_detector(age_net, gender_net) inside your main function and pass age_net and gender_net as its parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQLu4j6Iib4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   if __name__ == \"__main__\":\n",
        "age_net, gender_net = load_caffe_models()\n",
        "video_detector(age_net, gender_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GIu_3jPi0Ed",
        "colab_type": "text"
      },
      "source": [
        "## 1.2- BaggingClassifier \n",
        "We'll be explaining the usage of BaggingClassifier by using digits data set. We'll first train the model with default parameters and then do hyper-parameter tuning. We'll also be comparing the performance of tuned bagging estimator with decision tree and extra tree estimator of scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT-VLB8xjfuj",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 - Load DIGITS Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z3W2pYv-cTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = datasets.load_digits()\n",
        "X_digits, Y_digits = digits.data, digits.target\n",
        "print('Dataset Size : ', X_digits.shape, Y_digits.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wexnQdb59tZT",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 Splitting Dataset into Train & Test sets \n",
        "Below we are splitting the Boston dataset into train set(80%) and test set(20%). We are also using seed(random_state=123) so that we always get the same split and can reproduce results in the future as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luhIk0B-90rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, Y_digits, train_size=0.80, test_size=0.20, stratify=Y_digits, random_state=123)\n",
        "print('Train/Test Set Sizes : ',X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfhrppsrQ6pg",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.3 Fitting model on training Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewWWOuH-RGbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "bag_classifier = BaggingClassifier(random_state=1)\n",
        "bag_classifier.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRgocQiW9-dO",
        "colab_type": "text"
      },
      "source": [
        "###1.2.4 Evaluating Trained Model On Test Data ###\n",
        "Almost all models in Scikit-Learn API provides predict() method which can be used to predict target variable on Test Set passed to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zQ035HR-PEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " Y_preds = bag_classifier.predict(X_test)\n",
        "\n",
        "print(Y_preds[:15])\n",
        "print(Y_test[:15])\n",
        "\n",
        "print('Test Accuracy : %.3f'%(Y_preds == Y_test).mean())\n",
        "print('Test Accuracy : %.3f'%bag_classifier.score(X_test, Y_test)) ## Score method also evaluates accuracy for classification models.\n",
        "print('Training Accuracy : %.3f'%bag_classifier.score(X_train, Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIphSupp-dJ2",
        "colab_type": "text"
      },
      "source": [
        "###1.2.5- Finetuning Model By Doing Grid Search On Various Hyperparameters###\n",
        "BaggingClassifier has the same parameters to tune as that of BaggingRegressor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg4jUe2v-qYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "n_samples = digits.data.shape[0]\n",
        "n_features = digits.data.shape[1]\n",
        "\n",
        "params = {'base_estimator': [None, LogisticRegression(), KNeighborsClassifier()],\n",
        "          'n_estimators': [20,50,100],\n",
        "          'max_samples': [0.5, 1.0, n_samples//2, ],\n",
        "          'max_features': [0.5, 1.0, n_features//2, ],\n",
        "          'bootstrap': [True, False],\n",
        "          'bootstrap_features': [True, False]}\n",
        "\n",
        "bagging_classifier_grid = GridSearchCV(BaggingClassifier(random_state=1, n_jobs=-1), param_grid =params, cv=3, n_jobs=-1, verbose=1)\n",
        "bagging_classifier_grid.fit(X_train, Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%bagging_classifier_grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accurqacy : %.3f'%bagging_classifier_grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Accuracy Through Grid Search : %.3f'%bagging_classifier_grid.best_score_)\n",
        "print('Best Parameters : ',bagging_classifier_grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvO7qP_V-4oo",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.6 -Printing First Few Cross Validation Results###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRbBqF42_IYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(bagging_classifier_grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgLxzj33_PvP",
        "colab_type": "text"
      },
      "source": [
        "###1.2.7- Comparing Performance Of Bagging With Decision Tree/Extra Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgvLJ3YO_dYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag_classifier = ensemble.BaggingClassifier(random_state=1)\n",
        "bag_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(bag_classifier.__class__.__name__,\n",
        "                                                     bag_classifier.score(X_train, Y_train),bag_classifier.score(X_test, Y_test)))\n",
        "\n",
        "bag_classifier = ensemble.BaggingClassifier(base_estimator=KNeighborsClassifier(), random_state=1)\n",
        "bag_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(bag_classifier.__class__.__name__,\n",
        "                                                     bag_classifier.score(X_train, Y_train),bag_classifier.score(X_test, Y_test)))\n",
        "\n",
        "bag_classifier = ensemble.BaggingClassifier(random_state=1, **bagging_classifier_grid.best_params_)\n",
        "bag_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(bag_classifier.__class__.__name__,\n",
        "                                                     bag_classifier.score(X_train, Y_train),bag_classifier.score(X_test, Y_test)))\n",
        "\n",
        "dtree_classifier = tree.DecisionTreeClassifier(random_state=1)\n",
        "dtree_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(dtree_classifier.__class__.__name__,\n",
        "                                                     dtree_classifier.score(X_train, Y_train),dtree_classifier.score(X_test, Y_test)))\n",
        "\n",
        "extra_tree_classifier = tree.ExtraTreeClassifier(random_state=1)\n",
        "extra_tree_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(extra_tree_classifier.__class__.__name__,\n",
        "                                                     extra_tree_classifier.score(X_train, Y_train),extra_tree_classifier.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trbO8CCt_oMQ",
        "colab_type": "text"
      },
      "source": [
        "# 2 Random Forests \n",
        "Random Forests are slight improvements over bagging. Combining predictions from various decision trees works well when these decision trees predictions are as less correlated as possible. In a sense, each sub-tree is predicting some class of problem very well then all other sub-trees. The problem with bagging is that it’s a greedy algorithm like a single decision tree hence it tries to minimize error without looking for the optimal split. Due to this greedy approach, it fails to split data in a way that results in generating sub-trees which predicts uncorrelated results. When splitting a node during the construction of a tree, the split that is chosen is not best among all features. Instead split which is picked will be best on a random subset of features. It does not choose split which is best among all features.\n",
        "\n",
        "Random Forests changes algorithm in a way that when doing split it looks for all possible split and chooses optimal split which generates sub-trees that have less correlation. Random forests also average results of various sub-trees when doing prediction but it’s during training when doing an optimal split of data, it differs from Bagging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwgsBU4YUH0r",
        "colab_type": "text"
      },
      "source": [
        "**Extremely Randomized Trees**\n",
        "\n",
        "Scikit-Learn also provides another version of Random Forests which is further randomized in selecting split. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_QrDy9grtNT",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 RandomForestRegressor\n",
        "\n",
        "We'll be explaining the usage of RandomForestRegressor by using the Boston housing data set. We'll first train the model with default parameters and then do hyper-parameter tuning.# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X48Z7JqzGIpw",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 -Train/Test Split Boston Dataset###\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlAjNAu2GW-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " X_train, X_test, Y_train, Y_test = train_test_split(X_boston, Y_boston, train_size=0.80, test_size=0.20, random_state=123)\n",
        "print('Train/Test Sets Sizes : ',X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PBR08aHYFtN",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.2  Fitting Model To Train Data###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkN_apUzYRS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rforest_regressor = RandomForestRegressor(random_state=1)\n",
        "rforest_regressor.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TPHlG0jYYSI",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.3 Evaluating Trained Model On Test Data.###\n",
        "Almost all models in Scikit-Learn API provides predict() method which can be used to predict target varible on Test Set passed to it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6IZSh6AYmlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_preds = rforest_regressor.predict(X_test)\n",
        "\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])\n",
        "\n",
        "print('Training Coefficient of R^2 : %.3f'%rforest_regressor.score(X_train, Y_train))\n",
        "print('Test Coefficient of R^2 : %.3f'%rforest_regressor.score(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDMoh36qYtzI",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.4  Finetuning Model By Doing Grid Search On Various Hyperparameters###\n",
        "Below is a list of common hyperparameters that need tuning for getting the best fit for our data. We'll try various hyperparameters settings to various splits of train/test data to find out best fit which will have almost the same accuracy for both train & test dataset or have quite less difference between accuracy.\n",
        "\n",
        " - n_estimators - Number of base estimators whose results will be combined to produce final prediction. default=10\n",
        " - max_depth - It defines how finely tree can separate samples (list of \"if-else\" questions to ask deciding target variable). As we increase max_depth, model overfits and less value of max_depth results in underfit. We need to find best value. If no value is provided then by default None is used.\n",
        " - min_samples_split - Number of samples required to split internal node. It accepts int(0-n_samples), float(0.0-0.5] values. Float takes ceil(min_samples_split * n_samples) features.\n",
        " - min_samples_leaf - Minimum number of samples required to be at leaf node. It accepts int(0-n_samples), float(0.0-0.5] values. Float takes ceil(min_samples_leaf * n_samples) features.\n",
        " - criterion - Cost function which we algorithm tries to minimize. Currently it supports mse(mean squared error) & mae(mean absolute error).\n",
        " - max_features - Number of features to consider when doing split. It accepts int(0-n_features), float(0.0-0.5], string(sqrt, log2, auto) or None as value.\n",
        "   - None - n_features are used as value if None is provided.\n",
        "   - sqrt - sqrt(n_features) features are used for split.\n",
        "   - auto - sqrt(n_features) features are used for split.\n",
        "   = log2 - log2(n_features) features are used for split.\n",
        " - bootstrap - Decides whether samples are drawn with replacement. True = With Replacement. False = Without Replacement.default=True #* max_leaf_nodes -\n",
        "\n",
        "We'll below try various values for the above-mentioned hyper-parameters to find the best estimator for our dataset by doing 3-fold cross-validation on data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbyhqv9CYfBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "n_samples = X_boston.shape[0]\n",
        "n_features = X_boston.shape[1]\n",
        "\n",
        "params = {'n_estimators': [20,50,100],\n",
        "          'max_depth': [None, 2, 5],\n",
        "          'min_samples_split': [2, 0.5, n_samples//2, ],\n",
        "          'min_samples_leaf': [1, 0.5, n_samples//2, ],\n",
        "          'criterion': ['mse', 'mae'],\n",
        "          'max_features': [None, 'sqrt', 'auto', 'log2', 0.3,0.5, n_features//2,  ],\n",
        "          'bootstrap':[True, False]\n",
        "         }\n",
        "\n",
        "rf_regressor_grid = GridSearchCV(RandomForestRegressor(random_state=1), param_grid=params, n_jobs=-1, cv=3, verbose=1)\n",
        "rf_regressor_grid.fit(X_train,Y_train)\n",
        "\n",
        "print('Train R^2 Score : %.3f'%rf_regressor_grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test R^2 Score : %.3f'%rf_regressor_grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best R^2 Score Through Grid Search : %.3f'%rf_regressor_grid.best_score_)\n",
        "print('Best Parameters : ',rf_regressor_grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbRXXxlLZJQB",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.5  Printing First Few Cross Validation Results###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxs-NikBZYaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(rf_regressor_grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRKaQkCdZa_D",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 ExtraTreesRegressor###\n",
        "We'll be explaining the usage of ExtraTreesRegressor by using the Boston housing data set. We'll first train the model with default parameters and then do hyper-parameter tuning. We'll also be comparing the performance of tuned extra trees regression estimator with random forest, decision tree, and extra tree estimator of scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuAffqQUZtcc",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.1 Fitting Model To Train Data###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoywuS2eZz9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "extra_forest_regressor = ExtraTreesRegressor(random_state=1)\n",
        "extra_forest_regressor.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mxkYIRdZ_oh",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.2 Evaluating Trained Model On Test Data\n",
        "Almost all models in Scikit-Learn API provides predict() method which can be used to predict target variable on Test Set passed to it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwTLToFjfz9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_preds = extra_forest_regressor.predict(X_test)\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])\n",
        "print('Training Coefficient of R^2 : %.3f'%extra_forest_regressor.score(X_train, Y_train))\n",
        "print('Test Coefficient of R^2 : %.3f'%extra_forest_regressor.score(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYb8zKnyaT3j",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.3 Finetuning Model By Doing Grid Search On Various Hyperparameters.###\n",
        "ExtraTreesRegressor has the same parameters to tune as that of RandomForestRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_2pFKJNaY3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "n_samples = X_boston.shape[0]\n",
        "n_features = X_boston.shape[1]\n",
        "\n",
        "params = {'n_estimators': [20,50,100],\n",
        "          'max_depth': [None, 2,5,],\n",
        "          'min_samples_split': [2, 0.5, n_samples//2, ],\n",
        "          'min_samples_leaf': [1, 0.5, n_samples//2, ],\n",
        "          'criterion': ['mse', 'mae'],\n",
        "          'max_features': [None, 'sqrt', 'auto', 'log2', 0.3, 0.5, n_features//2],\n",
        "          'bootstrap':[True, False]\n",
        "         }\n",
        "\n",
        "ef_regressor_grid = GridSearchCV(ExtraTreesRegressor(random_state=1), param_grid=params, n_jobs=-1, cv=3, verbose=1)\n",
        "ef_regressor_grid.fit(X_train,Y_train)\n",
        "\n",
        "print('Train R^2 Score : %.3f'%ef_regressor_grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test R^2 Score : %.3f'%ef_regressor_grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best R^2 Score Through Grid Search : %.3f'%ef_regressor_grid.best_score_)\n",
        "print('Best Parameters : ',ef_regressor_grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELmUKHytaeSp",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.4 Printing First Few Cross Validation Results###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D4RHwLXanVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " cross_val_results = pd.DataFrame(ef_regressor_grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJzbZLezatfA",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.5  Comparing Performance Of Random Forest With Decision Tree/Extra Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iv9Oezpa7kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " rforest_regressor = ensemble.RandomForestRegressor(random_state=1)\n",
        "rforest_regressor.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(rforest_regressor.__class__.__name__,\n",
        "                                                     rforest_regressor.score(X_train, Y_train),rforest_regressor.score(X_test, Y_test)))\n",
        "\n",
        "rforest_regressor = ensemble.RandomForestRegressor(random_state=1, **rf_regressor_grid.best_params_)\n",
        "rforest_regressor.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(rforest_regressor.__class__.__name__,\n",
        "                                                     rforest_regressor.score(X_train, Y_train),rforest_regressor.score(X_test, Y_test)))\n",
        "\n",
        "\n",
        "extra_forest_regressor = ensemble.ExtraTreesRegressor(random_state=1)\n",
        "extra_forest_regressor.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(extra_forest_regressor.__class__.__name__,\n",
        "                                                     extra_forest_regressor.score(X_train, Y_train),extra_forest_regressor.score(X_test, Y_test)))\n",
        "\n",
        "extra_forest_regressor = ensemble.ExtraTreesRegressor(random_state=1, **ef_regressor_grid.best_params_)\n",
        "extra_forest_regressor.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(extra_forest_regressor.__class__.__name__,\n",
        "                                                     extra_forest_regressor.score(X_train, Y_train),extra_forest_regressor.score(X_test, Y_test)))\n",
        "\n",
        "dtree_regressor = tree.DecisionTreeRegressor(random_state=1)\n",
        "dtree_regressor.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(dtree_regressor.__class__.__name__,\n",
        "                                                     dtree_regressor.score(X_train, Y_train),dtree_regressor.score(X_test, Y_test)))\n",
        "\n",
        "extra_tree_regressor = tree.ExtraTreeRegressor(random_state=1)\n",
        "extra_tree_regressor.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(extra_forest_regressor.__class__.__name__,\n",
        "                                                     extra_tree_regressor.score(X_train, Y_train),extra_tree_regressor.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc2pIQwqbBWr",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 RandomForestClassifier##\n",
        "We'll be explaining the usage of RandomForestClassifier by using digits data set. We'll first train the model with default parameters and then do hyper-parameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vta4YRKmh8tA",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1 Train/Test Split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MuemGYtbMqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, Y_digits, train_size=0.80, test_size=0.20, random_state=123)\n",
        "print('Train/Test Sets Sizes : ',X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNUDVzM0bSLi",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2 Fitting Model To Train Data###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkefHNeVbbd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rforest_classifier = RandomForestClassifier(random_state=1)\n",
        "rforest_classifier.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVoEDoy7i2vR",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3 Evaluating Trained Model On Test Data\n",
        "Almost all models in Scikit-Learn API provides predict() method which can be used to predict target variable on Test Set passed to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCIcBUITjpan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_preds = rforest_classifier.predict(X_test)\n",
        "\n",
        "print(Y_preds[:15])\n",
        "print(Y_test[:15])\n",
        "\n",
        "print('Test Accuracy : %.3f'%(Y_preds == Y_test).mean() )\n",
        "print('Test Accuracy : %.3f'%rforest_classifier.score(X_test, Y_test)) ## Score method also evaluates accuracy for classification models.\n",
        "print('Training Accuracy : %.3f'%rforest_classifier.score(X_train, Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY7vkIbujzLo",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4 Finetuning Model By Doing Grid Search On Various Hyperparameters\n",
        "RandomForestClassifier has the same parameters to tune as that of RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH9KbsjOj6O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "n_samples = X_digits.shape[0]\n",
        "n_features = X_digits.shape[1]\n",
        "\n",
        "params = {'n_estimators': [20,50,100],\n",
        "          'max_depth': [None, 2, 5,],\n",
        "          'min_samples_split': [2, 0.5, n_samples//2, ],\n",
        "          'min_samples_leaf': [1, 0.5, n_samples//2, ],\n",
        "          'max_features': [None, 'sqrt', 'auto', 'log2', 0.3,0.5, n_features//2, ],\n",
        "          'bootstrap':[True, False]\n",
        "         }\n",
        "\n",
        "rf_classifier_grid = GridSearchCV(RandomForestClassifier(random_state=1), param_grid=params, n_jobs=-1, cv=3, verbose=1)\n",
        "rf_classifier_grid.fit(X_train,Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%rf_classifier_grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accurqacy : %.3f'%rf_classifier_grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Accuracy Through Grid Search : %.3f'%rf_classifier_grid.best_score_)\n",
        "print('Best Parameters : ',rf_classifier_grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duHTJ3RrkNk4",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.5 Printing First Few Cross Validation Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Hpv8LlkUsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(rf_classifier_grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urMpr121kgf4",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 ExtraTreesClassifier \n",
        "We'll be explaining the usage of ExtraTreesClassifier by using digits data set. We'll first train the model with default parameters and then do hyper-parameter tuning. We'll also be comparing the performance of tuned extra trees regression estimator with random forest, decision tree, and extra tree estimator of scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcVusWikkxws",
        "colab_type": "text"
      },
      "source": [
        "### 2.4.1  Fitting Model To Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40vmRfWJk7ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "extra_forest_classifier = ensemble.ExtraTreesClassifier(random_state=1)\n",
        "extra_forest_classifier.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av-1DtfblGat",
        "colab_type": "text"
      },
      "source": [
        "### 2.4.2 Evaluating Trained Model On Test Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od8IKHJmlNed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_preds = extra_forest_classifier.predict(X_test)\n",
        "print(Y_preds[:15])\n",
        "print(Y_test[:15])\n",
        "print('Test Accuracy : %.3f'%(Y_preds == Y_test).mean())\n",
        "print('Test Accuracy : %.3f'%extra_forest_classifier.score(X_test, Y_test)) ## Score method also evaluates accuracy for classification models.\n",
        "print('Training Accuracy : %.3f'%extra_forest_classifier.score(X_train, Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM9Da208lZGH",
        "colab_type": "text"
      },
      "source": [
        "### 2.4.3 Finetuning Model By Doing Grid Search On Various Hyperparameters\n",
        "ExtraTreesClassifier has the same parameters to tune as that of RandomForestRegressor/ExtraTreesRegressor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvrZ9FkWljXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "n_samples = X_digits.shape[0]\n",
        "n_features = X_digits.shape[1]\n",
        "\n",
        "params = {'n_estimators': [20,50,100],\n",
        "          'max_depth': [None, 2, 5,],\n",
        "          'min_samples_split': [2, 0.5, n_samples//2, ],\n",
        "          'min_samples_leaf': [1, 0.5, n_samples//2, ],\n",
        "          'max_features': [None, 'sqrt', 'auto', 'log2', 0.3,0.5, n_features//2, ],\n",
        "          'bootstrap':[True, False]\n",
        "         }\n",
        "\n",
        "ef_classifier_grid = GridSearchCV(ExtraTreesClassifier(random_state=1), param_grid=params, n_jobs=-1, cv=3, verbose=1)\n",
        "ef_classifier_grid.fit(X_train,Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%ef_classifier_grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accurqacy : %.3f'%ef_classifier_grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Accuracy Through Grid Search : %.3f'%ef_classifier_grid.best_score_)\n",
        "print('Best Parameters : ',ef_classifier_grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPQu1zCkl4Ln",
        "colab_type": "text"
      },
      "source": [
        "### 2.4.4 Printing First Few Cross Validation Results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIA5kB6ml9je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(ef_classifier_grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7TqgX-omRSE",
        "colab_type": "text"
      },
      "source": [
        "### 2.4.5 Comparing Performance Of Random Forest With Decision Tree/Extra Tree "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ism1yV7mmZXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rforest_classifier = ensemble.RandomForestClassifier(random_state=1)\n",
        "rforest_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(rforest_classifier.__class__.__name__,\n",
        "                                                     rforest_classifier.score(X_train, Y_train),rforest_classifier.score(X_test, Y_test)))\n",
        "\n",
        "rforest_classifier = ensemble.RandomForestClassifier(random_state=1, **rf_classifier_grid.best_params_)\n",
        "rforest_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(rforest_classifier.__class__.__name__,\n",
        "                                                     rforest_classifier.score(X_train, Y_train),rforest_classifier.score(X_test, Y_test)))\n",
        "\n",
        "extra_forest_classifier = ensemble.ExtraTreesClassifier(random_state=1)\n",
        "extra_forest_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(extra_forest_classifier.__class__.__name__,\n",
        "                                                     extra_forest_classifier.score(X_train, Y_train),extra_forest_classifier.score(X_test, Y_test)))\n",
        "\n",
        "extra_forest_classifier = ensemble.ExtraTreesClassifier(random_state=1, **ef_classifier_grid.best_params_)\n",
        "extra_forest_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(extra_forest_classifier.__class__.__name__,\n",
        "                                                     extra_forest_classifier.score(X_train, Y_train),extra_forest_classifier.score(X_test, Y_test)))\n",
        "\n",
        "dtree_classifier = tree.DecisionTreeClassifier(random_state=1)\n",
        "dtree_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(dtree_classifier.__class__.__name__,\n",
        "                                                     dtree_classifier.score(X_train, Y_train),dtree_classifier.score(X_test, Y_test)))\n",
        "\n",
        "extra_tree_classifier = tree.ExtraTreeClassifier(random_state=1)\n",
        "extra_tree_classifier.fit(X_train, Y_train)\n",
        "print(\"%s : Train Accuracy : %.2f, Test Accuracy : %.2f\"%(extra_tree_classifier.__class__.__name__,\n",
        "                                                     extra_tree_classifier.score(X_train, Y_train),extra_tree_classifier.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        " - [1] Gender and Age Detection Python Project\n",
        "\n",
        "https://data-flair.training/blogs/python-project-gender-age-detection/?fbclid=IwAR2YqS3yzlvQwqgkWuSjv4azyxkzSMamn97StQ0Vqm5KGy_7-2Sj4EoHVrI\n",
        " - [2] Adience Benchmark Gender And Age Classification\n",
        "https://towardsdatascience.com/predict-age-and-gender-using-convolutional-neural-network-and-opencv-fd90390e3ce6\n",
        "- [3] Gender and agge detection \n",
        "https://github.com/GilLevi/AgeGenderDeepLearning/tree/master/models\n",
        "\n",
        "- [4] Predict Age and Gender Using Convolutional Neural Network and OpenCV\n",
        "https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html\n",
        "\n",
        "- [5] Age and Gender Classification Using Convolutional Neural Networks\n",
        "https://talhassner.github.io/home/publication/2015_CVPR\n"
      ]
    }
  ]
}