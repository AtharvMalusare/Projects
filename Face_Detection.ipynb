{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Face Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Projects-/blob/master/Face_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS",
        "colab_type": "text"
      },
      "source": [
        "# Face detection with OpenCV and deep learning\n",
        "# **Introduction:**\n",
        "\n",
        "From there I’ll demonstrate how you can perform face detection in images using OpenCV and deep learning.In this first example we’ll learn how to apply face detection with OpenCV to single input images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpWN1sJv8eho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/hussain0048/Projects-"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnY7VuCDI-qN",
        "colab_type": "text"
      },
      "source": [
        "# 1 **Terminologies**#\n",
        "\n",
        "First introducing you with the terminologies used in this advanced python project of gender and age detection "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_aCyhDgoTRK",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 What is Computer Vision? \n",
        "Computer Vision is the field of study that enables computers to see and identify digital images and videos as a human would. The challenges it faces largely follow from the limited understanding of biological vision. Computer Vision involves acquiring, processing, analyzing, and understanding digital images to extract high-dimensional data from the real world in order to generate symbolic or numerical information which can then be used to make decisions. The process often includes practices like object recognition, video tracking, motion estimation, and image restoration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq4DpmTeRNNy",
        "colab_type": "text"
      },
      "source": [
        "##1.2 What is OpenC(VOpen Source Computer Vision)?\n",
        "OpenCV is short for Open Source Computer Vision. Intuitively by the name, it is an open-source Computer Vision and Machine Learning library. This library is capable of processing real-time image and video while also boasting analytical capabilities. It supports the Deep Learning frameworks TensorFlow, Caffe, and PyTorch.\n",
        "You can perform fast, accurate face detection with OpenCV using a pre-trained deep learning face detector model shipped with the library.\n",
        "\n",
        "You may already know that OpenCV ships out-of-the-box with pre-trained Haar cascades that can be used for face detection…\n",
        "\n",
        "With OpenCV 3.3, we can utilize pre-trained networks with popular deep learning frameworks. The fact that they are pre-trained implies that we don’t need to spend many hours training the network — rather we can complete a forward pass and utilize the output to make a decision within our application [7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT1IJkCnjkBb",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 dnn Module\n",
        "\n",
        "This module now supports a number of deep learning frameworks, including Caffe, TensorFlow, and Torch/PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSfzMhlNTrZS",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1  **Caffe models**\n",
        "When using OpenCV’s deep neural network module with Caffe models, you’ll need two sets of files:\n",
        "\n",
        "The .prototxt file(s) which define the model architecture (i.e., the layers themselves)\n",
        "The .caffemodel file which contains the weights for the actual layers\n",
        "Both files are required when using models trained using Caffe for deep learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV0K0tOIUteD",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 How does the OpenCV deep learning face detector work [6]?\n",
        "\n",
        "OpenCV’s deep learning face detector is based on the Single Shot Detector (SSD) framework with a ResNet base network (unlike other OpenCV SSDs that you may have seen which typically use MobileNet as the base network).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcVaahYFRsEF",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 What is a CNN?\n",
        "A Convolutional Neural Network is a deep neural network (DNN) widely used for the purposes of image recognition and processing and NLP. Also known as a ConvNet, a CNN has input and output layers, and multiple hidden layers, many of which are convolutional. In a way, CNNs are regularized multilayer perceptrons.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C_dTcsnSGFD",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 The CNN Architecture\n",
        "The convolutional neural network for this python project has 3 convolutional layers:\n",
        "- Convolutional layer; 96 nodes, kernel size 7\n",
        "- Convolutional layer; 256 nodes, kernel size 5\n",
        "- Convolutional layer; 384 nodes, kernel size 3\n",
        "\n",
        "It has 2 fully connected layers, each with 512 nodes, and a final output layer of softmax type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nhYP15aoCAcf",
        "colab_type": "text"
      },
      "source": [
        "# 2 - **Import library** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wsGi52CAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imutils\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQFJb0YzEYO",
        "colab_type": "text"
      },
      "source": [
        "#3 - **Start webcam and Caputure the picture** # "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqD8iiJZzTZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1CG9ZSRXCMO",
        "colab_type": "text"
      },
      "source": [
        "Click 'Capture' to make photo using your webcam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98UNaMMOW9Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_file = take_photo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldMGzlB4XTxh",
        "colab_type": "text"
      },
      "source": [
        "Read, resize and display the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRPSZImXXWA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image = cv2.imread(image_file, cv2.IMREAD_UNCHANGED)\n",
        "image = cv2.imread(image_file)\n",
        "# resize it to have a maximum width of 400 pixels\n",
        "image = imutils.resize(image, width=400)\n",
        "(h, w) = image.shape[:2]\n",
        "print(w,h)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpHsrVexXuWj",
        "colab_type": "text"
      },
      "source": [
        "##4-Download the pre-trained face detection model\n",
        "OpenCV’s deep learning face detector is based on the Single Shot Detector (SSD) framework with a ResNet base network. The network is defined and trained using the Caffe Deep Learning framework\n",
        "Download the pre-trained face detection model, consisting of two files:\n",
        "\n",
        "\n",
        "The network definition (deploy.prototxt)\n",
        "\n",
        "The learned weights (res10_300x300_ssd_iter_140000.caffemodel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia4AAHlC6Mhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
        "!wget -N https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL",
        "colab_type": "text"
      },
      "source": [
        "# 5- **Load the pre-trained face detection network model from disk**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JGZRKCCAcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " print(\"[INFO] loading model...\")\n",
        "prototxt = 'deploy.prototxt'\n",
        "model = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
        "net = cv2.dnn.readNetFromCaffe(prototxt, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q",
        "colab_type": "text"
      },
      "source": [
        "#6- **Resizing the image to a fixed 300x300 pixels** \n",
        "\n",
        "Use the dnn.blobFromImage function to construct an input blob by resizing the image to a fixed 300x300 pixels and then normalizing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resize it to have a maximum width of 400 pixels\n",
        "image = imutils.resize(image, width=400)\n",
        "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-",
        "colab_type": "text"
      },
      "source": [
        "# 7- **Computing object detections**\n",
        "Pass the blob through the neural network and obtain the detections and predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] computing object detections...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF",
        "colab_type": "text"
      },
      "source": [
        "# 8 - **Loop over the detections and draw boxes around the detected faces**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0, detections.shape[2]):\n",
        "\n",
        "\t# extract the confidence (i.e., probability) associated with the prediction\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t# filter out weak detections by ensuring the `confidence` is\n",
        "\t# greater than the minimum confidence threshold\n",
        "\tif confidence > 0.5:\n",
        "\t\t# compute the (x, y)-coordinates of the bounding box for the object\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\t\t# draw the bounding box of the face along with the associated probability\n",
        "\t\ttext = \"{:.2f}%\".format(confidence * 100)\n",
        "\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "\t\tcv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "\t\tcv2.putText(image, text, (startX, y),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPVRQUagaObK",
        "colab_type": "text"
      },
      "source": [
        "Show the resulting image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUJ16arHaKMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        " - [1] Gender and Age Detection Python Project\n",
        "\n",
        "https://data-flair.training/blogs/python-project-gender-age-detection/?fbclid=IwAR2YqS3yzlvQwqgkWuSjv4azyxkzSMamn97StQ0Vqm5KGy_7-2Sj4EoHVrI\n",
        " - [2] Adience Benchmark Gender And Age Classification\n",
        "https://towardsdatascience.com/predict-age-and-gender-using-convolutional-neural-network-and-opencv-fd90390e3ce6\n",
        "- [3] Gender and agge detection \n",
        "https://github.com/GilLevi/AgeGenderDeepLearning/tree/master/models\n",
        "\n",
        "- [4] Predict Age and Gender Using Convolutional Neural Network and OpenCV\n",
        "https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html\n",
        "\n",
        "- [5] Age and Gender Classification Using Convolutional Neural Networks\n",
        "https://talhassner.github.io/home/publication/2015_CVPR\n",
        "\n",
        "-[6]Face detection with OpenCV and deep learning\n",
        "]https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/\n",
        "\n",
        "[7] Deep Learning with OpenCV\n",
        "https://www.pyimagesearch.com/2017/08/21/deep-learning-with-opencv/\n",
        "\n",
        "[8] Object detection with deep learning and OpenCV\n",
        "https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/\n",
        "\n"
      ]
    }
  ]
}