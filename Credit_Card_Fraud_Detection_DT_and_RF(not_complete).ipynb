{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card Fraud Detection_DT and RF(not complete).ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3UKROvBhtn+GB+VMZkyNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Projects-/blob/master/Credit_Card_Fraud_Detection_DT_and_RF(not_complete).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwSTf-Rr4C7P",
        "colab_type": "text"
      },
      "source": [
        "# **1-Introduction**\n",
        "\n",
        "Fraud transactions or fraudulent activities are significant issues in many industries like banking, insurance, etc. Especially for the banking industry, credit card fraud detection is a pressing issue to resolve.\n",
        "\n",
        "These industries suffer too much due to fraudulent activities towards revenue growth and lose customer’s trust. So these companies need to find fraud transactions before it becomes a big problem for them.  \n",
        "\n",
        "Unlike the other machine learning problems, in credit card fraud detection the target class distribution is not equally distributed. It is popularly known as the class imbalance problem or unbalanced data issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt8hBkep4fV1",
        "colab_type": "text"
      },
      "source": [
        "#**2-Why do we need to find fraud transactions?**\n",
        "\n",
        "For many companies, fraud detection is a big problem because they find these fraudulent activities after they experience high loss. \n",
        "\n",
        "Fraud activities happen in all  industries. We can't say only particular companies/industries suffer from these fraudulent activities or transactions. \n",
        "\n",
        "But when it comes to financial-related companies, this fraud transaction becomes more of an issue/problem.  So these companies want to detect fraud transactions before the fraud activities turn into significant damage to their company.\n",
        "\n",
        "In the current generation, with high-end technology, still, on every 100 credit card transactions, 13% are falling into the fraudulent activities reported by the creditcards website.\n",
        "\n",
        "A survey paper mentioned that in the year 1997, 63% of companies experienced one fraud in the past two years, and in another year 1999, 57% of companies experienced at least one fraud in the last one year. \n",
        "\n",
        "Here the point is not only fraud activities increase, but the way of doing scams also increases badly. \n",
        "\n",
        "Companies suffer from detecting fraud, and due to these fraudulent activities, many companies worldwide have lost billions of dollars yearly.\n",
        "\n",
        "And one more thing, for any company, customer's trust is more important to achieve or reach some position in the business marketplace. If a company cannot find these fraudulent activities, companies lose customer's trust; then, they will suffer from customer churn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fi7ViZW5NbW",
        "colab_type": "text"
      },
      "source": [
        "#**3-Fraud Detection Approaches**\n",
        "\n",
        "First, companies hire few people only for the detection of these kinds of activities or transactions. But here they must and should be experts in this field or domain, and also the team should have knowledge of how frauds occur in particular domains. This requires more resources, such as people's effort and time.\n",
        "\n",
        "Second, companies changed manual processes to rule-based solutions. But this one also fails most of the time to detect frauds. \n",
        "\n",
        "Because in the real world, the way of doing frauds is changing drastically day by day. These rule-based systems follow some rules and conditions. If a new fraud process is different from others, then these systems fail. It requires adding that new rule to code and execute. \n",
        "\n",
        "Now companies are trying to adopt Artificial Intelligence or machine learning algorithms to detect frauds. Machine learning algorithms performed very well for this type of problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA_s4yn65nfs",
        "colab_type": "text"
      },
      "source": [
        "#**4-What is Credit Card Fraud Detection?**\n",
        "\n",
        "In the above section, we discussed the need for identifying fraudulent activities. The credit card fraud classification problem is used to find fraud transactions or fraudulent activities before they become a major problem to credit card companies. \n",
        "\n",
        "It uses the combination of fraud and non-fraud transactions from the historical data with different people's credit card transaction data to estimate fraud or non-fraud on credit card transactions.\n",
        "\n",
        "In this article, we are using the popular credit card dataset. Let’s understand the data before we start building the fraud detection models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIvt0S5654v6",
        "colab_type": "text"
      },
      "source": [
        "#**5-Understanding of Credit Card Dataset**\n",
        "\n",
        "For this credit card fraud classification problem, we are using the dataset which was downloaded from the Kaggle platform. \n",
        "\n",
        "You can find and download the dataset from here.\n",
        "\n",
        "Before going to the model development part, we should have some knowledge about our dataset\n",
        "\n",
        "Such as \n",
        "\n",
        "- What is the size of the dataset?\n",
        "- How many features does the dataset have?\n",
        "- What are the target values?\n",
        "- How many samples under each target value? , etc.\n",
        "\n",
        "If we know some information about the dataset, then we can decide what we have to do?. \n",
        "\n",
        "What are the questions we discussed above, all  we can explore by using the python pandas library. \n",
        "\n",
        "Let's jump to the data exploration part to find answers to all questions we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N21ciYRb6wSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uL3U6-r8KJw",
        "colab_type": "text"
      },
      "source": [
        "#**6-Data Explorations**\n",
        "First, we need to load the dataset. After downloading the dataset, extract the data and keep the file in the dataset under the project folder. \n",
        "\n",
        "We can quickly load it using pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWxze98F8rSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# load dataset\n",
        "fraud_df = pd.read_csv(\"/content/drive/My Drive/Datasets/Credit Card Detection/creditcard.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NpLewGl9CKY",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is a CSV(Comma Separated Values) file. We can use the read_csv function from pandas to read the file. \n",
        "\n",
        "Ok, now find the answers for our above dataset related questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "536S4RFq9D4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jrpXL_vFYO1",
        "colab_type": "text"
      },
      "source": [
        "Dataset has 284807 rows and 31 features. The result of the shape variable is a tuple that has the number of rows, number of columns of the dataset.\n",
        "\n",
        "We can see how the dataset looks like. The below command showcases  only five rows, head() by default, gives 5 samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zORhfK21Fdx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkThq5P9F528",
        "colab_type": "text"
      },
      "source": [
        "If you want to see more samples from the top, pass the number representing the number of samples you want to see like fraud_df.head(10). \n",
        "\n",
        "You can also see bottom samples by using the tail() function. Both are working in the same way.\n",
        "\n",
        "We can get all the list of feature names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ4h3KimGCqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTDPDFj9GXix",
        "colab_type": "text"
      },
      "source": [
        "From this, we know Class is the target variable, and the remaining all are features of our dataset.\n",
        "\n",
        "Let's see what are the unique values we are having for the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OSglPDdGZUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df['Class'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoqA_pEUGhKw",
        "colab_type": "text"
      },
      "source": [
        "The target variable Class has 0 and 1 values. Here\n",
        "\n",
        "- 0 for non-fraudulent transactions\n",
        "- 1 for fraudulent transactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGX9jajfGt-a",
        "colab_type": "text"
      },
      "source": [
        "Because we aim to find fraudulent transactions, the dataset's target value has a positive value for that. \n",
        "\n",
        "Still, What is pending in data exploration questions? \n",
        "\n",
        "yeah, we have to check how many samples each target class is having."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNXHbS2qG04Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqr3DqkhG9OD",
        "colab_type": "text"
      },
      "source": [
        "Yeah, we have 284315 non-fraudulent transaction samples & 492 fraudulent transaction samples.\n",
        "\n",
        "We will discuss more about the data in the later sections of this article. \n",
        "\n",
        "You are going to know the variation of this number of samples and how much impact on the model's performance, how we can evaluate model performance for this data, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifMQzUXcHB5j",
        "colab_type": "text"
      },
      "source": [
        "Still, now you only know about the dataset, such\n",
        "\n",
        "- Dataset size\n",
        "- Number of samples(rows) and features(columns)\n",
        "- Names of the features\n",
        "- About target variables, etc.\n",
        "\n",
        "Now we will discuss different data preprocessing techniques for our dataset. \n",
        "\n",
        "The data preprocessing techniques will be completely different from the text preprocessing techniques we discussed in the natural language processing data preprocessing techniques article"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX7ufPeFHvNI",
        "colab_type": "text"
      },
      "source": [
        "#**7-Credit Card Data Preprocessing**\n",
        "\n",
        "Preprocessing is the process of cleaning the dataset. In this step, we will apply different methods to clean the raw data to feed more meaningful data for the modeling phase. This method includes\n",
        "\n",
        "- Remove duplicates or irrelevant samples\n",
        "- Update missing values with the most relevant values \n",
        "- Convert one data type to another example, categorical to integers, etc.\n",
        "\n",
        "Okay, now we will spend a couple of minutes checking the dataset and applying corresponding techniques to clean data. \n",
        "\n",
        "This step aims to improve the quality of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAEGgJGuIhn8",
        "colab_type": "text"
      },
      "source": [
        "**Removing irrelevant columns/features**\n",
        "\n",
        "In our dataset, only one irrelevant or not useful feature id Time. So we can drop that feature from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLJVVKXtI3YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure which features are useful & which are not\n",
        "# we can remove irrelevant features\n",
        "fraud_df = fraud_df.drop(['Time'], axis=1)\n",
        "fraud_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLhETWzILjWO",
        "colab_type": "text"
      },
      "source": [
        "If you want to drop more features from data, call drop() method with a list of feature names. \n",
        "\n",
        "We can observe no feature name Time in the list of feature names after dropping the Time feature/column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynSzPAimLn9N",
        "colab_type": "text"
      },
      "source": [
        "**Checking null or nan values**\n",
        "\n",
        "We can check the datatypes of all features and, at the same time, the number of non-null values of all features by using info() of pandas. \n",
        "\n",
        "Null or nan values are nothing, but there is no value for that particular feature or attribute.\n",
        "\n",
        "For example, these nan or null values are coming if the customer or user does not fill all information in the forms. Blank values are treated as null or nan values. \n",
        "\n",
        "It's okay; we can know all this information just by using info() from pandas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeeRf0CUL-Oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnferGK-MhyU",
        "colab_type": "text"
      },
      "source": [
        "See the values of the Amount feature values are in high range compared to other feature values. \n",
        "\n",
        "We will change values within a smaller range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "islCkWF8Mx5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "fraud_df['norm_amount'] = StandardScaler().fit_transform(\n",
        "fraud_df['Amount'].values.reshape(-1,1))\n",
        "fraud_df = fraud_df.drop(['Amount'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcnzD_z-M0a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df['norm_amount'][0:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9phdEe8YNCRe",
        "colab_type": "text"
      },
      "source": [
        "The scalar result is added as a new column with norm_amount name to the data frame after we drop the Amount column because there is no use with it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEnThpboNPDL",
        "colab_type": "text"
      },
      "source": [
        "#**8-Splitting dataset**\n",
        "\n",
        "Now we will take all independent columns (target column is dependent and the remaining all are independent columns to each other), as X and the target variable as y.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StdSXVI8NZOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Features and target creations\n",
        "X = fraud_df.drop(['Class'], axis=1)\n",
        "y = fraud_df[['Class']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHCpSnyANdS6",
        "colab_type": "text"
      },
      "source": [
        "Now we need to split the whole dataset into train and test dataset. Training data is used at the time of building the model and a test dataset is used to evaluate trained models. \n",
        "\n",
        "By using the train_test_split method from the sklearn library we can do this process of splitting the dataset to train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8vWuUR8NfFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting dataset to train & test dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc34wmSENygT",
        "colab_type": "text"
      },
      "source": [
        "Now our dataset is ready for building models. Let's jump to the development of  the model using machine learning algorithms such as decision tree and random forest classification algorithms from the sklearn module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr8u4ShfOAIe",
        "colab_type": "text"
      },
      "source": [
        "#**9-Building Credit Card Fraud Detection using Machine Learning algorithms**\n",
        "\n",
        "Now we can build models using different machine learning algorithms. Before creating a model, we need to find the type of problem statement, which means is supervised or unsupervised algorithm\n",
        "\n",
        "Our problem statement falls under the supervised learning problem means the dataset has a target value for each row or sample in the dataset. \n",
        "\n",
        "Supervised machine learning algorithms are two types \n",
        "\n",
        "- Classification Algorithms\n",
        "- Regression Algorithms\n",
        "\n",
        "Our problem statement belongs to what type of algorithms? \n",
        "\n",
        "Yeah, exactly.\n",
        "\n",
        "Credit card fraud detection is a classification problem. Target variable values of Classification problems have integer(0,1) or categorical values(fraud, non-fraud). The target variable of our dataset ‘Class’ has only two labels - 0 (non-fraudulent) and 1 (fraudulent).\n",
        "\n",
        "Before going further let us give an introduction for both decision tree classification and random forest classification. As in this article, we are going to use these two algorithms to build the credit card fraudulent activities identification model.\n",
        "\n",
        "- Decision Tree Classification Algorithm\n",
        "- Random Forest Classification Algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHv4G5WZPCgq",
        "colab_type": "text"
      },
      "source": [
        "**Decision Tree Algorithm Overview**\n",
        "\n",
        "The decision tree is the simplest and most popular classification algorithm. For building the model the decision tree algorithm considers all the provided features of the data and comes up with the important features.\n",
        "\n",
        "Because of this advantage, the decision tree algorithms also used in identifying the importance of the feature metrics. Which used in handpicking the features. \n",
        "\n",
        "Once the important features identified then the model trains with the training data to come up with a set of rules. These rules used in predicting future cases or for the test dataset. \n",
        "\n",
        "This is a quick overview of the decision tree algorithm. If you want to learn more about the algorithm and implement in python, have a look at the below articles written by our team.\n",
        "- [How the decision tree learns from the training data](https://dataaspirant.com/how-decision-tree-algorithm-works/)\n",
        "\n",
        "- [BUILDING DECISION TREE ALGORITHM IN PYTHON WITH SCIKIT LEARN](https://dataaspirant.com/decision-tree-algorithm-python-with-scikit-learn/)\n",
        "\n",
        "- [How to visuvalizing the decsion tree](https://dataaspirant.com/visualize-decision-tree-python-graphviz/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42RF8GVrRCpe",
        "colab_type": "text"
      },
      "source": [
        "**Random Forest Algorithm Overview**\n",
        "\n",
        "The random forest algorithm falls under the ensemble learning algorithm category. In the random forest algorithm, we build N decision tree models.  \n",
        "\n",
        "All the models predict the target value. Using the majority voting approach the final target value will be predicted.\n",
        "\n",
        "For building the individual decision tree, the random forest algorithm randomly creates the sample dataset. These sample datasets are called as the bootstrap samples.\n",
        "\n",
        "Suppose we want to build the N decision trees to create the forest, the algorithm first creates N bootstrap samples. Later for each bootstrap sample, one decision tree model will build.\n",
        "\n",
        "This is a quick overview of the random forest algorithm, If you want to learn more, please have a look at the below articles.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbjUv_IDUdFR",
        "colab_type": "text"
      },
      "source": [
        "- [How bootstrap samples created in Ensembleme learning methods.](https://dataaspirant.com/ensemble-methods-bagging-vs-boosting-difference/)\n",
        "- [End to end the working nature of the Random forest algorithm.](https://dataaspirant.com/random-forest-algorithm-machine-learing/)\n",
        "- [Implementing the Random forest algorithm in python.](https://dataaspirant.com/random-forest-classifier-python-scikit-learn/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEQp4vu7VVsf",
        "colab_type": "text"
      },
      "source": [
        "#**10-Credit Card Fraud Detection with Decision Tree Algorithm**\n",
        "\n",
        "We will use the DecisionTreeClassifier class from the sklearn library to train and evaluate models. We use X_train and y_train data for training purposes. X_train is a training dataset with features, and y_train is the target label.\n",
        "\n",
        "**Decision tree algorithm Implementation using python sklearn library**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWHL8Xf2VrCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Building decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
        "    # initialize object for DecisionTreeClassifier class\n",
        "    dt_classifier = DecisionTreeClassifier()\n",
        "    # train model by using fit method\n",
        "    print(\"Model training starts........\")\n",
        "    dt_classifier.fit(X_train, y_train.values.ravel())\n",
        "    print(\"Model training completed\")\n",
        "    acc_score = dt_classifier.score(X_test, y_test)\n",
        "    print(f'Accuracy of model on test dataset :- {acc_score}')\n",
        "    # predict result using test dataset\n",
        "    y_pred = dt_classifier.predict(X_test)\n",
        "    # confusion matrix\n",
        "    print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
        "    # classification report for f1-score\n",
        "    print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lhphVKjV1Vl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f5af9f8b-f7f3-4b22-d1aa-1b8a721f6365"
      },
      "source": [
        "# calling decision_tree_classification method to train and evaluate model\n",
        "decision_tree_classification(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model training starts........\n",
            "Model training completed\n",
            "Accuracy of model on test dataset :- 0.9992626663389628\n",
            "Confusion Matrix :- \n",
            " [[85268    28]\n",
            " [   35   112]]\n",
            "Classification Report :- \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.80      0.76      0.78       147\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.90      0.88      0.89     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv3NZqcLXtz1",
        "colab_type": "text"
      },
      "source": [
        "Wow, our decision tree classification gives 99% accuracy on test data. \n",
        "\n",
        "But why f1-score on label 1 too less ?. \n",
        "\n",
        "Remember this point; we will discuss these metrics performances in the coming section of this article where we address the question\n",
        "\n",
        "Why the accuracy evaluation metric is not suitable for this problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQnqJeuqXyam",
        "colab_type": "text"
      },
      "source": [
        "#**11-Credit Card Fraud Detection with Random Forest Algorithm**\n",
        "\n",
        "Same as the above decision tree implementation, we use X_train and y_train dataset for training purposes and X_test for evaluation. Here we train the ensemble technique model of RandomForestClassifier from the sklearn. We can see the variations in the evaluation results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zMeYXcoYGYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Model with randomforest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
        "     # initialize object for DecisionTreeClassifier class\n",
        "     rf_classifier = RandomForestClassifier(n_estimators=50)\n",
        "     # train model by using fit method\n",
        "     print(\"Model training starts........\")\n",
        "     rf_classifier.fit(X_train, y_train.values.ravel())\n",
        "     acc_score = rf_classifier.score(X_test, y_test)\n",
        "     print(f'Accuracy of model on test dataset :- {acc_score}')\n",
        "     # predict result using test dataset\n",
        "     y_pred = rf_classifier.predict(X_test)\n",
        "     # confusion matrix\n",
        "     print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
        "     # classification report for f1-score\n",
        "     print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anQt7J52YYUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calling random_forest_classifier\n",
        "random_forest_classifier(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7URffYwDaWP",
        "colab_type": "text"
      },
      "source": [
        "Wow, this model's accuracy is also 99% great, but what about remaining evaluation metrics such as precision, recall, F1-score. \n",
        "\n",
        "Let's discuss these variations why it happens, all these in the coming section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoEMns2zDctL",
        "colab_type": "text"
      },
      "source": [
        "#**12-Why Accuracy not suitable for Data Imbalance Problems?**\n",
        "\n",
        "What was the reason for not applying or not considering accuracy as a performance metric for this specific problem?\n",
        "\n",
        "Just take some time, think about it.\n",
        "\n",
        "Model training is completed; we got accuracy on the test set as 99%. \n",
        "\n",
        "But why this section? \n",
        "\n",
        "We are having various classification evaluation metrics to quantify the performance of the build model, accuracy is one method in that. What other methods we can apply?\n",
        "\n",
        "Now we will discuss our dataset and what are the best evaluation metrics for these kinds of problems.\n",
        "\n",
        "For this discussion, we have to remember two things that are previously discussed.\n",
        "\n",
        "- The number of samples for each Class (target variable) value.\n",
        "- Evaluation metrics at both the decision tree and random forest classification models.\n",
        "\n",
        "Do you remember the number of samples/rows for each target value? \n",
        "\n",
        "No? okay, let us check that number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVh0VA89EImC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4NhO4mAEUDQ",
        "colab_type": "text"
      },
      "source": [
        "See the number of samples for Class-1 (fraudulent) less than the samples for class-0 (non-fraudulent). \n",
        "\n",
        "This kind of dataset is called **unbalanced data.** Which means one class label samples are  higher and dominating the other class label. \n",
        "\n",
        "For a balanced dataset, accuracy is suitable because we take the divided value of the correctly predicted samples count with the total number of samples for accuracy. \n",
        "\n",
        "**Accuracy = number of correctly predicted samples / total number of samples**\n",
        "\n",
        "For example. \n",
        "\n",
        "If our dataset has 20 samples, out of that 2 for Class 0 & 18 for Class 1. Our trained model correctly predicted 17 samples out of 18 Class-1 samples and 0 samples out of 2 Class-0 samples. \n",
        "\n",
        "What is the accuracy value for this? 85%.\n",
        "\n",
        "But this is not correct, right? Because the model doesn’t even predict one sample correctly for Class-0 samples, but we got 85% accuracy. \n",
        "\n",
        "For an unbalanced dataset, a list of evaluation metrics are available. In the next section, we will discuss this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QagpZ5svEyPe",
        "colab_type": "text"
      },
      "source": [
        "#**12-Suitable evaluation metrics for imbalanced data**\n",
        "So which all metrics are suitable for unbalanced data?\n",
        "\n",
        "We can use any of the below-mentioned metrics for unbalanced or skewed datasets.\n",
        "\n",
        "- Recall\n",
        "- Precision\n",
        "- F1-score\n",
        "- Area Under ROC curve.\n",
        "\n",
        "We can see the huge difference among different evaluation metrics for both classifications (decision tree & random forest) models. \n",
        "\n",
        "Do you remember we mentioned at model development stage, accuracy, classification report, etc. ? \n",
        "\n",
        "Okay, let see the results here\n",
        "\n",
        "Here we have to discuss a few terms and formulae related to confusion matrix, precision, recall & F1-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vGYORbrHMa0",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1ztL9HmbaUAbHmDiQoOcZ49nvpydWC_E9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs6niLpyHava",
        "colab_type": "text"
      },
      "source": [
        "**True Positive (TP):-**  \n",
        "The number of positive labels correctly predicted by trained models.  This means the number of Class-1 samples correctly predicted as Class-1.\n",
        "\n",
        "**True Negative (TN):-**\n",
        "The number of negative labels correctly predicted by trained models.  This means the number of Class-0 samples correctly predicted as Class-0.\n",
        "\n",
        "**False Positive (FP):-  **\n",
        "The number of positive labels incorrectly predicted by trained models. This means the number of Class-1 samples incorrectly predicted as Class-0.\n",
        "\n",
        "**False Negative (FN):-**  \n",
        "The number of negative labels incorrectly predicted by trained models.  This means the number of Class-0 samples incorrectly predicted as Class-1.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "- Recall = TP / (TP + FN)\n",
        "- Precision = TP / (TP + FP)\n",
        "- F1-Score = 2*P*R / (P + R) here P for Precision, R for Recall\n",
        "\n",
        "Both classification models got accuracy scores as 99%. \n",
        "\n",
        "But when we observe the result of the classification report of both classifiers, f1-score for Class-0 got 100%, but for Class-1, F1-scores are significantly less. \n",
        "\n",
        "All these variations occur due to the unbalanced or skewed dataset. \n",
        "\n",
        "Why f1-score for class-0 100%? \n",
        "\n",
        "Because of the number of samples for class-0 (2 lakhs). The number of samples for Class-0 is very high than the Class-1 samples.\n",
        "\n",
        "So what we need to do here is handle an unbalanced dataset. If you want to learn more about it, check the Best ways to handle unbalanced data in the machine learning article which explained various ways to handle the imbalanced data.\n",
        "\n",
        "One more thing is left for discussion in this section, which is about areas under the ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq4SiZZhIV61",
        "colab_type": "text"
      },
      "source": [
        "#**13-AUC and ROC CurveS**\n",
        "\n",
        "Area Under ROC curve is another evaluation metric for classification problems. This is mostly suitable for skewed datasets. It tells us about model performance, such as the model's capability to distinguish between target classes. \n",
        "\n",
        "The effective model has a higher Area Under the ROC curve value. Here we measure the ability of class separability of a model by using the Area Under ROC curve.\n",
        "\n",
        "Good models have AUC value near to 1, and the worst models have AUC value near 0.\n",
        "\n",
        "All the model performance methods help in the measuring the performance of the model based on the problem, but how to build the best models when we face with the data imbalance issue?\n",
        "\n",
        "For that, we need to apply different sampling methods to the data before building the models.\n",
        "\n",
        "Let’s see how sampling methods improve model performance, and how much AUC score for that model in the coming section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeA-_qXAI6eZ",
        "colab_type": "text"
      },
      "source": [
        "#**14-Model Improvement Using Sampling Techniques**\n",
        "\n",
        "Data sampling is the statistical method for selecting data points (here, the data point is a single row) from the whole dataset. In machine learning problems, there are many sampling techniques available.\n",
        "\n",
        "Here we take **undersampling** and **oversampling** strategies for handling imbalanced data. \n",
        "\n",
        "**What is this undersampling and oversampling?** \n",
        "\n",
        "Let us take an example of a dataset that has nine samples. \n",
        "\n",
        "- Six samples belong to class-0,\n",
        "- Three samples belong to class-1\n",
        "\n",
        "**Oversampling** = 6 class-0 samples x  2 times of class-1 samples of 3\n",
        "\n",
        "**Undersampling** = 3 Class-1 samples x 3 samples from Class-0\n",
        "\n",
        "Here what we are trying to do is the number of samples of both target classes to be equal. \n",
        "\n",
        "In the oversampling technique, samples are repeated, and the dataset size is larger than the original dataset.\n",
        "\n",
        "In the undersampling technique, samples are not repeated, and the dataset size is less than the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdu2IgCaKDqB",
        "colab_type": "text"
      },
      "source": [
        "#**15 Applying Sampling Techniques**\n",
        "\n",
        "For undersampling techniques, we are checking the number of samples of both classes and selecting the smaller number and taking random samples from other class samples to create a new dataset.  \n",
        "\n",
        "The new dataset has an equal number of samples for both target classes.\n",
        "\n",
        "This is a whole process of undersampling, and now we are going to implement this entire process using python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTPxOTwKSOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Target class distribution\n",
        "class_val = fraud_df['Class'].value_counts()\n",
        "print(f\"Number of samples for each class :- \\n {class_val}\")\n",
        "non_fraud = class_val[0]\n",
        "fraud = class_val[1]\n",
        "print(f\"Non Fraudulent Numbers :- {non_fraud}\")\n",
        "print(f\"Fraudulent Numbers :- {fraud}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHzGl0g8KXSg",
        "colab_type": "text"
      },
      "source": [
        "The above is the target class distributions, now let's see how we can change this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugR-BmI_KazA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Equal both the target samples to the same level\n",
        "# take indexes of non fraudulent\n",
        "nonfraud_indexies = fraud_df[fraud_df.Class == 0].index\n",
        "fraud_indices = np.array(fraud_df[fraud_df['Class'] == 1].index)\n",
        "# take random samples from non fraudulent that are equal to fraudulent samples\n",
        "random_normal_indexies = np.random.choice(nonfraud_indexies, fraud, replace=False)\n",
        "random_normal_indexies = np.array(random_normal_indexies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNMnYj4_KmUj",
        "colab_type": "text"
      },
      "source": [
        "Here first, we take indexes of both classes and randomly choose Class-0 samples indexes that are equal to the number of Class-1 samples. \n",
        "\n",
        "In the below code snippet, Combine both classes indexes. Then we extract all features of gathered indexes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EACMjhD9KrHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Equal both the target samples to the same level\n",
        "# take indexes of non fraudulent\n",
        "nonfraud_indexies = fraud_df[fraud_df.Class == 0].index\n",
        "fraud_indices = np.array(fraud_df[fraud_df['Class'] == 1].index)\n",
        "# take random samples from non fraudulent that are equal to fraudulent samples\n",
        "random_normal_indexies = np.random.choice(nonfraud_indexies, fraud, replace=False)\n",
        "random_normal_indexies = np.array(random_normal_indexies)\n",
        "\n",
        "\n",
        "## Undersampling techniques\n",
        "\n",
        "# concatenate both indices of fraud and non fraud\n",
        "under_sample_indices = np.concatenate([fraud_indices, random_normal_indexies])\n",
        "\n",
        "#extract all features from whole data for under sample indices only\n",
        "under_sample_data = fraud_df.iloc[under_sample_indices, :]\n",
        "\n",
        "# now we have to divide under sampling data to all features & target\n",
        "x_undersample_data = under_sample_data.drop(['Class'], axis=1)\n",
        "y_undersample_data = under_sample_data[['Class']]\n",
        "# now split dataset to train and test datasets as before\n",
        "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(\n",
        "x_undersample_data, y_undersample_data, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTlqR0CaKwMq",
        "colab_type": "text"
      },
      "source": [
        "The above code first divides features and targets as x_undersample_data and y_undersample_data and then splits new undersample data into train and test dataset.\n",
        "\n",
        "Okay, now we will call both classifiers with these new under sampling train and test datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9NPaaCwK2Wg",
        "colab_type": "text"
      },
      "source": [
        "#**16-Decision tree classification after applying sampling techniques**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keJ3pit6LAeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DecisionTreeClassifier after applying undersampling technique\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
        " # initialize object for DecisionTreeClassifier class\n",
        " dt_classifier = DecisionTreeClassifier()\n",
        " # train model by using fit method\n",
        " print(\"Model training start........\")\n",
        " dt_classifier.fit(X_train, y_train.values.ravel())\n",
        " print(\"Model training completed\")\n",
        " acc_score = dt_classifier.score(X_test, y_test)\n",
        " print(f'Accuracy of model on test dataset :- {acc_score}')\n",
        " # predict result using test dataset\n",
        " y_pred = dt_classifier.predict(X_test)\n",
        " # confusion matrix\n",
        " print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
        " # classification report for f1-score\n",
        " print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
        " print(f\"AROC score :- \\n {roc_auc_score(y_test, y_pred)}\")\n",
        "\n",
        "# calling decision tree classifier function \n",
        "decision_tree_classification(X_train_sample, y_train_sample, \n",
        "X_test_sample, y_test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTKVYn-kLGDv",
        "colab_type": "text"
      },
      "source": [
        "#**17-Random Forest Tree Classifier after applying the sampling technique**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu-noRJqLNq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## RandomForestClassifier after apply the undersampling techniques\n",
        "\n",
        "from sklearn.tree import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
        " # initialize object for DecisionTreeClassifier class\n",
        " rf_classifier = RandomForestClassifier(n_estimators=50)\n",
        " # train model by using fit method\n",
        " print(\"Model training start........\")\n",
        " rf_classifier.fit(X_train, y_train.values.ravel())\n",
        " acc_score = rf_classifier.score(X_test, y_test)\n",
        " print(f'Accuracy of model on test dataset :- {acc_score}')\n",
        " # predict result using test dataset\n",
        " y_pred = rf_classifier.predict(X_test)\n",
        " # confusion matrix\n",
        " print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
        " # classification report for f1-score\n",
        " print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
        " # area under roc curve\n",
        " print(f\"AROC score :- \\n {roc_auc_score(y_test, y_pred)}\")\n",
        "\n",
        "random_forest_classifier(X_train_sample, y_train_sample, X_test_sample, y_test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLh4R5WeLVH5",
        "colab_type": "text"
      },
      "source": [
        "See, the results of the F1-score for both target values are 95%, and the Area Under ROC curve is near to 1. \n",
        "\n",
        "For the best models, we have the AUROC value near to 1. Here we implemented the undersampling technique; you can apply oversampling also like an undersampling process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyWjZ4oP3wZe",
        "colab_type": "text"
      },
      "source": [
        "# **References**\n",
        "[[1]Credit Card Fraud Detection](https://dataaspirant.com/credit-card-fraud-detection-classification-algorithms-python/?fbclid=IwAR2s8dv8K2ETBEJYbYWNiLSpbfBqR_iG7YvBOdene8z7TJk7EedTab8YYG0)"
      ]
    }
  ]
}