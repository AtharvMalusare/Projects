{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPk02rl+hdt02rxA/FV8JcJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Projects/blob/master/Traffic_Sign_Classification_with_Keras_and_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2-qLumoBqQe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Introduction**"
      ],
      "metadata": {
        "id": "blvh0tqoCOSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the first part of this tutorial, we’ll discuss the concept of traffic sign classification and recognition, including the dataset we’ll be using to train our own custom traffic sign classifier.We’ll then implement TrafficSignNet, a Convolutional Neural Network which we’ll train on our dataset.\n",
        "\n",
        "Given our trained model we’ll evaluate its accuracy on the test data and even learn how to make predictions on new input data as well."
      ],
      "metadata": {
        "id": "AFEB2oPaEFXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is traffic sign classification?**\n"
      ],
      "metadata": {
        "id": "Xi9hivCaEdT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traffic sign classification is the process of automatically recognizing traffic signs along the road, including speed limit signs, yield signs, merge signs, etc. Being able to automatically recognize traffic signs enables us to build “smarter cars”.\n",
        "\n",
        "Self-driving cars need traffic sign recognition in order to properly parse and understand the roadway. Similarly, “driver alert” systems inside cars need to understand the roadway around them to help aid and protect drivers.\n",
        "\n",
        "Traffic sign recognition is just one of the problems that computer vision and deep learning can solve."
      ],
      "metadata": {
        "id": "CgumbgpFE1gC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Traffic sign dataset**"
      ],
      "metadata": {
        "id": "kgNZcqE6FFJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we’ll be using to train our own custom traffic sign classifier is the German Traffic Sign Recognition Benchmark (GTSRB).\n",
        "\n"
      ],
      "metadata": {
        "id": "yxzog4mqFbrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GTSRB dataset consists of 43 traffic sign classes and nearly 50,000 images."
      ],
      "metadata": {
        "id": "bc-23EVjFltR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the real-world, traffic sign recognition is a two-stage process:\n",
        "\n",
        "Localization: Detect and localize where in an input image/frame a traffic sign is.\n",
        "Recognition: Take the localized ROI and actually recognize and classify the traffic sign.\n",
        "Deep learning object detectors can perform localization and recognition in a single forward-pass of the network — if you’re interested in learning more about object detection and traffic sign localization using Faster R-CNNs, Single Shot Detectors (SSDs), and RetinaNet, be sure to refer to my book, Deep Learning for Computer Vision with Python, where I cover the topic in detail."
      ],
      "metadata": {
        "id": "ZKzH4irdF0dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Challenges with the GTSRB dataset**"
      ],
      "metadata": {
        "id": "9pSTHHnVHc9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a number of challenges in the GTSRB dataset, the first being that images are low resolution, and worse, have poor contrast (as seen in Figure 2 above). These images are pixelated, and in some cases, it’s extremely challenging, if not impossible, for the human eye and brain to recognize the sign.\n",
        "\n",
        "The second challenge with the dataset is handling class skew:"
      ],
      "metadata": {
        "id": "Ttu5WTV3HxYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top class (Speed limit 50km/h) has over 2,000 examples while the least represented class (Speed limit 20km/h) has under 200 examples — that’s an order of magnitude difference!\n",
        "\n",
        "In order to successfully train an accurate traffic sign classifier we’ll need to devise an experiment that can:\n",
        "\n",
        "Preprocess our input images to improve contrast.\n",
        "Account for class label skew."
      ],
      "metadata": {
        "id": "KQXGJ-FuH7vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuring your development environment**\n"
      ],
      "metadata": {
        "id": "MqG50Y_bIaZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this article, you’ll need to have the following packages installed:\n",
        "\n",
        "1. OpenCV\n",
        "2. NumPy\n",
        "3. scikit-learn\n",
        "4. scikit-image\n",
        "5. imutils\n",
        "6. matplotlib\n",
        "7. TensorFlow 2.0 (CPU or GPU)\n",
        "\n",
        "Luckily each of these is easily installed with pip, a Python package manager.\n",
        "\n",
        "Let’s install the packages now, ideally into a virtual environment as shown (you’ll need to create the environment):"
      ],
      "metadata": {
        "id": "lUISQe-AIv5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install opencv-contrib-python\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install scikit-image\n",
        "!pip install imutils\n",
        "!pip install matplotlib\n",
        "!pip install tensorflow==2.0.0 # or tensorflow-gpu"
      ],
      "metadata": {
        "id": "-lA0pqLKJHiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "5oDGvyRdKaDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "pJSY7GqoKhS0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficSignNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "    # CONV => RELU => BN => POOL\n",
        "\t\tmodel.add(Conv2D(8, (5, 5), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # first set of (CONV => RELU => CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\t# second set of (CONV => RELU => CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # first set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(128))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\t\t# second set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(128))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "metadata": {
        "id": "abdIwWHZK5f_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "# import the necessary packages\n",
        "#from pyimagesearch.trafficsignnet import TrafficSignNet\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from skimage import transform\n",
        "from skimage import exposure\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "rsomP2eUM9rp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_split(basePath, csvPath):\n",
        "\t# initialize the list of data and labels\n",
        "\tdata = []\n",
        "\tlabels = []\n",
        "\t# load the contents of the CSV file, remove the first line (since\n",
        "\t# it contains the CSV header), and shuffle the rows (otherwise\n",
        "\t# all examples of a particular class will be in sequential order)\n",
        "\trows = open(csvPath).read().strip().split(\"\\n\")[1:]\n",
        "\trandom.shuffle(rows)\n",
        " # loop over the rows of the CSV file\n",
        "\tfor (i, row) in enumerate(rows):\n",
        "\t\t# check to see if we should show a status update\n",
        "\t\tif i > 0 and i % 1000 == 0:\n",
        "\t\t\tprint(\"[INFO] processed {} total images\".format(i))\n",
        "\t\t# split the row into components and then grab the class ID\n",
        "\t\t# and image path\n",
        "\t\t(label, imagePath) = row.strip().split(\",\")[-2:]\n",
        "\t\t# derive the full path to the image file and load it\n",
        "\t\timagePath = os.path.sep.join([basePath, imagePath])\n",
        "\t\timage = io.imread(imagePath)"
      ],
      "metadata": {
        "id": "5OeJaR0tNNEB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**References**"
      ],
      "metadata": {
        "id": "WeXOPxIIB412"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1-Traffic Sign Classification with Keras and Deep Learning](https://pyimagesearch.com/2019/11/04/traffic-sign-classification-with-keras-and-deep-learning/)"
      ],
      "metadata": {
        "id": "XfR0KHaqB_T2"
      }
    }
  ]
}