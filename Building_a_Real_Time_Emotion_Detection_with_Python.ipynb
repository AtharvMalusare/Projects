{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Building a Real Time Emotion Detection with Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Projects-/blob/master/Building_a_Real_Time_Emotion_Detection_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS",
        "colab_type": "text"
      },
      "source": [
        "# Building a Real Time Emotion Detection with Python\n",
        "# **Introduction:**\n",
        "\n",
        "Detecting real-time emotion of the person with a camera input is one of the advanced features in the machine learning process. The detection of emotion of a person using a camera is useful for various research and analytics purposes. The detection of emotion is made by using the machine learning concept. You can use the trained dataset to detect the emotion of the human being. For detecting the different emotions, first you need to train those different emotions, or you can use a dataset already available on the internet. In this article, we will discuss creating a Python program to detect real-time emotion of a human being using the camera '[1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAVZc4ayyDWL",
        "colab_type": "text"
      },
      "source": [
        "# 1-Installing Dependencies "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpWN1sJv8eho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWA9EJ-zwyej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensor flow "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6X6cfXcw4uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le9Nov-7w7X6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To capture video from webcam.   \n",
        "cap = cv2.VideoCapture(0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mznrdFXIxGES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:  \n",
        "    # Read the frame  \n",
        "    _, img = cap.read()  \n",
        "  \n",
        "    # Convert to grayscale  \n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
        "  \n",
        "    # Detect the faces  \n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)  \n",
        "  \n",
        "    # Draw the rectangle around each face  \n",
        "    for (x, y, w, h) in faces:  \n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)  \n",
        "  \n",
        "    # Display  \n",
        "    cv2.imshow('Video', img)  \n",
        "  \n",
        "    # Stop if escape key is pressed  \n",
        "    k = cv2.waitKey(30) & 0xff  \n",
        "    if k==27:  \n",
        "        break  \n",
        "          \n",
        "# Release the VideoCapture object  \n",
        "cap.release()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnY7VuCDI-qN",
        "colab_type": "text"
      },
      "source": [
        "# 1 **Terminologies**#\n",
        "\n",
        "First introducing you with the terminologies used in this advanced python project of gender and age detection "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_aCyhDgoTRK",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 What is Computer Vision? \n",
        "Computer Vision is the field of study that enables computers to see and identify digital images and videos as a human would. The challenges it faces largely follow from the limited understanding of biological vision. Computer Vision involves acquiring, processing, analyzing, and understanding digital images to extract high-dimensional data from the real world in order to generate symbolic or numerical information which can then be used to make decisions. The process often includes practices like object recognition, video tracking, motion estimation, and image restoration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq4DpmTeRNNy",
        "colab_type": "text"
      },
      "source": [
        "##1.2 What is OpenC(VOpen Source Computer Vision)?\n",
        "OpenCV is short for Open Source Computer Vision. Intuitively by the name, it is an open-source Computer Vision and Machine Learning library. This library is capable of processing real-time image and video while also boasting analytical capabilities. It supports the Deep Learning frameworks TensorFlow, Caffe, and PyTorch.\n",
        "You can perform fast, accurate face detection with OpenCV using a pre-trained deep learning face detector model shipped with the library.\n",
        "\n",
        "You may already know that OpenCV ships out-of-the-box with pre-trained Haar cascades that can be used for face detection…\n",
        "\n",
        "With OpenCV 3.3, we can utilize pre-trained networks with popular deep learning frameworks. The fact that they are pre-trained implies that we don’t need to spend many hours training the network — rather we can complete a forward pass and utilize the output to make a decision within our application [7]\n",
        "\n",
        "With OpenCV 3.3, we can utilize pre-trained networks with popular deep learning frameworks. The fact that they are pre-trained implies that we don’t need to spend many hours training the network — rather we can complete a forward pass and utilize the output to make a decision within our application.\n",
        "\n",
        "OpenCV does not (and does not intend to be) to be a tool for training networks — there are already great frameworks available for that purpose. Since a network (such as a CNN) can be used as a classifier, it makes logical sense that OpenCV has a Deep Learning module that we can leverage easily within the OpenCV ecosystem [7].\n",
        "\n",
        "Popular network architectures compatible with OpenCV 3.3 include:\n",
        "\n",
        "- GoogleLeNet (used in this blog post)\n",
        "- AlexNet\n",
        "- SqueezeNet\n",
        "- VGGNet (and associated flavors)\n",
        "- ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT1IJkCnjkBb",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 dnn Module\n",
        "\n",
        "This module now supports a number of deep learning frameworks, including Caffe, TensorFlow, and Torch/PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSfzMhlNTrZS",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1  **Caffe models**\n",
        "When using OpenCV’s deep neural network module with Caffe models, you’ll need two sets of files:\n",
        "\n",
        "The .prototxt file(s) which define the model architecture (i.e., the layers themselves)\n",
        "The .caffemodel file which contains the weights for the actual layers\n",
        "Both files are required when using models trained using Caffe for deep learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV0K0tOIUteD",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 How does the OpenCV deep learning face detector work [6]?\n",
        "\n",
        "OpenCV’s deep learning face detector is based on the Single Shot Detector (SSD) framework with a ResNet base network (unlike other OpenCV SSDs that you may have seen which typically use MobileNet as the base network).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcVaahYFRsEF",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 What is a CNN?\n",
        "A Convolutional Neural Network is a deep neural network (DNN) widely used for the purposes of image recognition and processing and NLP. Also known as a ConvNet, a CNN has input and output layers, and multiple hidden layers, many of which are convolutional. In a way, CNNs are regularized multilayer perceptrons.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C_dTcsnSGFD",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 The CNN Architecture\n",
        "The convolutional neural network for this python project has 3 convolutional layers:\n",
        "- Convolutional layer; 96 nodes, kernel size 7\n",
        "- Convolutional layer; 256 nodes, kernel size 5\n",
        "- Convolutional layer; 384 nodes, kernel size 3\n",
        "\n",
        "It has 2 fully connected layers, each with 512 nodes, and a final output layer of softmax type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nhYP15aoCAcf",
        "colab_type": "text"
      },
      "source": [
        "# 2 - **Import library** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wsGi52CAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils.video import VideoStream\n",
        "from imutils.video import FPS\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQFJb0YzEYO",
        "colab_type": "text"
      },
      "source": [
        "#3 - **Start webcam and Caputure the picture** # "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqD8iiJZzTZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-p\", \"--prototxt\", required=True,\n",
        "\thelp=\"path to Caffe 'deploy' prototxt file\")\n",
        "ap.add_argument(\"-m\", \"--model\", required=True,\n",
        "\thelp=\"path to Caffe pre-trained model\")\n",
        "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.2,\n",
        "\thelp=\"minimum probability to filter weak detections\")\n",
        "args = vars(ap.parse_args())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1CG9ZSRXCMO",
        "colab_type": "text"
      },
      "source": [
        "Click 'Capture' to make photo using your webcam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98UNaMMOW9Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_file = take_photo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldMGzlB4XTxh",
        "colab_type": "text"
      },
      "source": [
        "Read, resize and display the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRPSZImXXWA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image = cv2.imread(image_file, cv2.IMREAD_UNCHANGED)\n",
        "image = cv2.imread(image_file)\n",
        "# resize it to have a maximum width of 400 pixels\n",
        "image = imutils.resize(image, width=400)\n",
        "(h, w) = image.shape[:2]\n",
        "print(w,h)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpHsrVexXuWj",
        "colab_type": "text"
      },
      "source": [
        "##4-Download the pre-trained face detection model\n",
        "OpenCV’s deep learning face detector is based on the Single Shot Detector (SSD) framework with a ResNet base network. The network is defined and trained using the Caffe Deep Learning framework\n",
        "Download the pre-trained face detection model, consisting of two files:\n",
        "\n",
        "\n",
        "The network definition (deploy.prototxt)\n",
        "\n",
        "The learned weights (res10_300x300_ssd_iter_140000.caffemodel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia4AAHlC6Mhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
        "!wget -N https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL",
        "colab_type": "text"
      },
      "source": [
        "# 5- **Load the pre-trained face detection network model from disk**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JGZRKCCAcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " print(\"[INFO] loading model...\")\n",
        "prototxt = 'deploy.prototxt'\n",
        "model = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
        "net = cv2.dnn.readNetFromCaffe(prototxt, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q",
        "colab_type": "text"
      },
      "source": [
        "#6- **Resizing the image to a fixed 300x300 pixels** \n",
        "\n",
        "Use the dnn.blobFromImage function to construct an input blob by resizing the image to a fixed 300x300 pixels and then normalizing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resize it to have a maximum width of 400 pixels\n",
        "image = imutils.resize(image, width=400)\n",
        "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-",
        "colab_type": "text"
      },
      "source": [
        "# 7- **Computing object detections**\n",
        "Pass the blob through the neural network and obtain the detections and predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] computing object detections...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF",
        "colab_type": "text"
      },
      "source": [
        "# 8 - **Loop over the detections and draw boxes around the detected faces**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0, detections.shape[2]):\n",
        "\n",
        "\t# extract the confidence (i.e., probability) associated with the prediction\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t# filter out weak detections by ensuring the `confidence` is\n",
        "\t# greater than the minimum confidence threshold\n",
        "\tif confidence > 0.5:\n",
        "\t\t# compute the (x, y)-coordinates of the bounding box for the object\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\t\t# draw the bounding box of the face along with the associated probability\n",
        "\t\ttext = \"{:.2f}%\".format(confidence * 100)\n",
        "\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "\t\tcv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "\t\tcv2.putText(image, text, (startX, y),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPVRQUagaObK",
        "colab_type": "text"
      },
      "source": [
        "Show the resulting image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUJ16arHaKMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "[1] Building a Real Time Emotion Detection with Python\n",
        "\n",
        "https://morioh.com/p/801c509dda99?f=5c21f93bc16e2556b555ab2f\n",
        "\n"
      ]
    }
  ]
}