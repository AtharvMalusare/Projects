{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card Fraud Detection(not complete).ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIPEfy+M3zTJzB1xYFtfPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Projects-/blob/master/Credit_Card_Fraud_Detection(not_complete).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwSTf-Rr4C7P",
        "colab_type": "text"
      },
      "source": [
        "# **1-Introduction**\n",
        "\n",
        "Fraud transactions or fraudulent activities are significant issues in many industries like banking, insurance, etc. Especially for the banking industry, credit card fraud detection is a pressing issue to resolve.\n",
        "\n",
        "These industries suffer too much due to fraudulent activities towards revenue growth and lose customer’s trust. So these companies need to find fraud transactions before it becomes a big problem for them.  \n",
        "\n",
        "Unlike the other machine learning problems, in credit card fraud detection the target class distribution is not equally distributed. It is popularly known as the class imbalance problem or unbalanced data issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt8hBkep4fV1",
        "colab_type": "text"
      },
      "source": [
        "#**2-Why do we need to find fraud transactions?**\n",
        "\n",
        "For many companies, fraud detection is a big problem because they find these fraudulent activities after they experience high loss. \n",
        "\n",
        "Fraud activities happen in all  industries. We can't say only particular companies/industries suffer from these fraudulent activities or transactions. \n",
        "\n",
        "But when it comes to financial-related companies, this fraud transaction becomes more of an issue/problem.  So these companies want to detect fraud transactions before the fraud activities turn into significant damage to their company.\n",
        "\n",
        "In the current generation, with high-end technology, still, on every 100 credit card transactions, 13% are falling into the fraudulent activities reported by the creditcards website.\n",
        "\n",
        "A survey paper mentioned that in the year 1997, 63% of companies experienced one fraud in the past two years, and in another year 1999, 57% of companies experienced at least one fraud in the last one year. \n",
        "\n",
        "Here the point is not only fraud activities increase, but the way of doing scams also increases badly. \n",
        "\n",
        "Companies suffer from detecting fraud, and due to these fraudulent activities, many companies worldwide have lost billions of dollars yearly.\n",
        "\n",
        "And one more thing, for any company, customer's trust is more important to achieve or reach some position in the business marketplace. If a company cannot find these fraudulent activities, companies lose customer's trust; then, they will suffer from customer churn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fi7ViZW5NbW",
        "colab_type": "text"
      },
      "source": [
        "#**3-Fraud Detection Approaches**\n",
        "\n",
        "First, companies hire few people only for the detection of these kinds of activities or transactions. But here they must and should be experts in this field or domain, and also the team should have knowledge of how frauds occur in particular domains. This requires more resources, such as people's effort and time.\n",
        "\n",
        "Second, companies changed manual processes to rule-based solutions. But this one also fails most of the time to detect frauds. \n",
        "\n",
        "Because in the real world, the way of doing frauds is changing drastically day by day. These rule-based systems follow some rules and conditions. If a new fraud process is different from others, then these systems fail. It requires adding that new rule to code and execute. \n",
        "\n",
        "Now companies are trying to adopt Artificial Intelligence or machine learning algorithms to detect frauds. Machine learning algorithms performed very well for this type of problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA_s4yn65nfs",
        "colab_type": "text"
      },
      "source": [
        "#**4-What is Credit Card Fraud Detection?**\n",
        "\n",
        "In the above section, we discussed the need for identifying fraudulent activities. The credit card fraud classification problem is used to find fraud transactions or fraudulent activities before they become a major problem to credit card companies. \n",
        "\n",
        "It uses the combination of fraud and non-fraud transactions from the historical data with different people's credit card transaction data to estimate fraud or non-fraud on credit card transactions.\n",
        "\n",
        "In this article, we are using the popular credit card dataset. Let’s understand the data before we start building the fraud detection models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIvt0S5654v6",
        "colab_type": "text"
      },
      "source": [
        "#**5-Understanding of Credit Card Dataset**\n",
        "\n",
        "For this credit card fraud classification problem, we are using the dataset which was downloaded from the Kaggle platform. \n",
        "\n",
        "You can find and download the dataset from here.\n",
        "\n",
        "Before going to the model development part, we should have some knowledge about our dataset\n",
        "\n",
        "Such as \n",
        "\n",
        "- What is the size of the dataset?\n",
        "- How many features does the dataset have?\n",
        "- What are the target values?\n",
        "- How many samples under each target value? , etc.\n",
        "\n",
        "If we know some information about the dataset, then we can decide what we have to do?. \n",
        "\n",
        "What are the questions we discussed above, all  we can explore by using the python pandas library. \n",
        "\n",
        "Let's jump to the data exploration part to find answers to all questions we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N21ciYRb6wSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b992ff1-ba0f-4eec-9026-d883f641bb4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uL3U6-r8KJw",
        "colab_type": "text"
      },
      "source": [
        "#**6-Data Explorations**\n",
        "First, we need to load the dataset. After downloading the dataset, extract the data and keep the file in the dataset under the project folder. \n",
        "\n",
        "We can quickly load it using pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3pg57-27NMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"/content/drive/My Drive/Datasets/Credit Card Detection /creditcard.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWxze98F8rSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# load dataset\n",
        "fraud_df = pd.read_csv(\"/content/drive/My Drive/Datasets/Credit Card Detection/creditcard.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NpLewGl9CKY",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is a CSV(Comma Separated Values) file. We can use the read_csv function from pandas to read the file. \n",
        "\n",
        "Ok, now find the answers for our above dataset related questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "536S4RFq9D4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jrpXL_vFYO1",
        "colab_type": "text"
      },
      "source": [
        "Dataset has 284807 rows and 31 features. The result of the shape variable is a tuple that has the number of rows, number of columns of the dataset.\n",
        "\n",
        "We can see how the dataset looks like. The below command showcases  only five rows, head() by default, gives 5 samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zORhfK21Fdx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkThq5P9F528",
        "colab_type": "text"
      },
      "source": [
        "If you want to see more samples from the top, pass the number representing the number of samples you want to see like fraud_df.head(10). \n",
        "\n",
        "You can also see bottom samples by using the tail() function. Both are working in the same way.\n",
        "\n",
        "We can get all the list of feature names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ4h3KimGCqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTDPDFj9GXix",
        "colab_type": "text"
      },
      "source": [
        "From this, we know Class is the target variable, and the remaining all are features of our dataset.\n",
        "\n",
        "Let's see what are the unique values we are having for the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OSglPDdGZUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df['Class'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoqA_pEUGhKw",
        "colab_type": "text"
      },
      "source": [
        "The target variable Class has 0 and 1 values. Here\n",
        "\n",
        "- 0 for non-fraudulent transactions\n",
        "- 1 for fraudulent transactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGX9jajfGt-a",
        "colab_type": "text"
      },
      "source": [
        "Because we aim to find fraudulent transactions, the dataset's target value has a positive value for that. \n",
        "\n",
        "Still, What is pending in data exploration questions? \n",
        "\n",
        "yeah, we have to check how many samples each target class is having."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNXHbS2qG04Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fraud_df['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqr3DqkhG9OD",
        "colab_type": "text"
      },
      "source": [
        "Yeah, we have 284315 non-fraudulent transaction samples & 492 fraudulent transaction samples.\n",
        "\n",
        "We will discuss more about the data in the later sections of this article. \n",
        "\n",
        "You are going to know the variation of this number of samples and how much impact on the model's performance, how we can evaluate model performance for this data, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifMQzUXcHB5j",
        "colab_type": "text"
      },
      "source": [
        "Still, now you only know about the dataset, such\n",
        "\n",
        "- Dataset size\n",
        "- Number of samples(rows) and features(columns)\n",
        "- Names of the features\n",
        "- About target variables, etc.\n",
        "\n",
        "Now we will discuss different data preprocessing techniques for our dataset. \n",
        "\n",
        "The data preprocessing techniques will be completely different from the text preprocessing techniques we discussed in the natural language processing data preprocessing techniques article"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX7ufPeFHvNI",
        "colab_type": "text"
      },
      "source": [
        "#**7-Credit Card Data Preprocessing**\n",
        "\n",
        "Preprocessing is the process of cleaning the dataset. In this step, we will apply different methods to clean the raw data to feed more meaningful data for the modeling phase. This method includes\n",
        "\n",
        "- Remove duplicates or irrelevant samples\n",
        "- Update missing values with the most relevant values \n",
        "- Convert one data type to another example, categorical to integers, etc.\n",
        "\n",
        "Okay, now we will spend a couple of minutes checking the dataset and applying corresponding techniques to clean data. \n",
        "\n",
        "This step aims to improve the quality of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAEGgJGuIhn8",
        "colab_type": "text"
      },
      "source": [
        "**Removing irrelevant columns/features**\n",
        "\n",
        "In our dataset, only one irrelevant or not useful feature id Time. So we can drop that feature from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLJVVKXtI3YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure which features are useful & which are not\n",
        "# we can remove irrelevant features\n",
        "fraud_df = fraud_df.drop(['Time'], axis=1)\n",
        "fraud_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyWjZ4oP3wZe",
        "colab_type": "text"
      },
      "source": [
        "# **References**\n",
        "[[1]Credit Card Fraud Detection](https://dataaspirant.com/credit-card-fraud-detection-classification-algorithms-python/?fbclid=IwAR2s8dv8K2ETBEJYbYWNiLSpbfBqR_iG7YvBOdene8z7TJk7EedTab8YYG0)"
      ]
    }
  ]
}